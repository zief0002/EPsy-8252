<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Unit 4: Probability Distributions | EPsy 8252 Notes</title>
  <meta name="description" content="These are the notes for EPsy 8252.">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="Unit 4: Probability Distributions | EPsy 8252 Notes />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="These are the notes for EPsy 8252." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Unit 4: Probability Distributions | EPsy 8252 Notes />
  
  <meta name="twitter:description" content="These are the notes for EPsy 8252." />
  

<meta name="author" content="Andrew Zieffler">


<meta name="date" content="2018-12-31">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="log-transformations-some-final-thoughts.html">
<link rel="next" href="maximum-likelihood-estimation.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<link href="libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet" />
<script src="libs/pagedtable-1.1/js/pagedtable.js"></script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">EPsy 8252 Notes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction to the Course</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#course-content"><i class="fa fa-check"></i>Course Content</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#books-and-other-reading-materials"><i class="fa fa-check"></i>Books and Other Reading Materials</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#prerequisites"><i class="fa fa-check"></i>Prerequisites</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="rmarkdown.html"><a href="rmarkdown.html"><i class="fa fa-check"></i><b>1</b> R Markdown</a><ul>
<li class="chapter" data-level="" data-path="rmarkdown.html"><a href="rmarkdown.html#preparation"><i class="fa fa-check"></i>Preparation</a></li>
<li class="chapter" data-level="" data-path="rmarkdown.html"><a href="rmarkdown.html#notes"><i class="fa fa-check"></i>Notes</a></li>
<li class="chapter" data-level="" data-path="rmarkdown.html"><a href="rmarkdown.html#other-resources"><i class="fa fa-check"></i>Other Resources</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="nonlinearity-log-transforming-the-predictor.html"><a href="nonlinearity-log-transforming-the-predictor.html"><i class="fa fa-check"></i><b>2</b> Nonlinearity: Log-Transforming the Predictor</a><ul>
<li class="chapter" data-level="" data-path="nonlinearity-log-transforming-the-predictor.html"><a href="nonlinearity-log-transforming-the-predictor.html#preparation-1"><i class="fa fa-check"></i>Preparation</a></li>
<li class="chapter" data-level="2.1" data-path="nonlinearity-log-transforming-the-predictor.html"><a href="nonlinearity-log-transforming-the-predictor.html#dataset-and-research-question"><i class="fa fa-check"></i><b>2.1</b> Dataset and Research Question</a></li>
<li class="chapter" data-level="2.2" data-path="nonlinearity-log-transforming-the-predictor.html"><a href="nonlinearity-log-transforming-the-predictor.html#log-transformation-of-a-variable"><i class="fa fa-check"></i><b>2.2</b> Log-Transformation of a Variable</a><ul>
<li class="chapter" data-level="2.2.1" data-path="nonlinearity-log-transforming-the-predictor.html"><a href="nonlinearity-log-transforming-the-predictor.html#quick-refresher-on-logarithms"><i class="fa fa-check"></i><b>2.2.1</b> Quick Refresher on Logarithms</a></li>
<li class="chapter" data-level="2.2.2" data-path="nonlinearity-log-transforming-the-predictor.html"><a href="nonlinearity-log-transforming-the-predictor.html#log-transforming-variables"><i class="fa fa-check"></i><b>2.2.2</b> Log-Transforming Variables</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="nonlinearity-log-transforming-the-predictor.html"><a href="nonlinearity-log-transforming-the-predictor.html#fitting-the-regression-model"><i class="fa fa-check"></i><b>2.3</b> Fitting the Regression Model</a><ul>
<li class="chapter" data-level="2.3.1" data-path="nonlinearity-log-transforming-the-predictor.html"><a href="nonlinearity-log-transforming-the-predictor.html#examine-the-assumption-of-linearity"><i class="fa fa-check"></i><b>2.3.1</b> Examine the Assumption of Linearity</a></li>
<li class="chapter" data-level="2.3.2" data-path="nonlinearity-log-transforming-the-predictor.html"><a href="nonlinearity-log-transforming-the-predictor.html#interpret-the-regression-results"><i class="fa fa-check"></i><b>2.3.2</b> Interpret the Regression Results</a></li>
<li class="chapter" data-level="2.3.3" data-path="nonlinearity-log-transforming-the-predictor.html"><a href="nonlinearity-log-transforming-the-predictor.html#better-interpretations-back-transforming"><i class="fa fa-check"></i><b>2.3.3</b> Better Interpretations: Back-transforming</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="nonlinearity-log-transforming-the-predictor.html"><a href="nonlinearity-log-transforming-the-predictor.html#alternative-method-of-fitting-the-model"><i class="fa fa-check"></i><b>2.4</b> Alternative Method of Fitting the Model</a></li>
<li class="chapter" data-level="2.5" data-path="nonlinearity-log-transforming-the-predictor.html"><a href="nonlinearity-log-transforming-the-predictor.html#plotting-the-fitted-model"><i class="fa fa-check"></i><b>2.5</b> Plotting the Fitted Model</a></li>
<li class="chapter" data-level="2.6" data-path="nonlinearity-log-transforming-the-predictor.html"><a href="nonlinearity-log-transforming-the-predictor.html#different-base-values-in-the-logarithm"><i class="fa fa-check"></i><b>2.6</b> Different Base Values in the Logarithm</a><ul>
<li class="chapter" data-level="2.6.1" data-path="nonlinearity-log-transforming-the-predictor.html"><a href="nonlinearity-log-transforming-the-predictor.html#comparing-the-output-from-the-two-bases"><i class="fa fa-check"></i><b>2.6.1</b> Comparing the Output from the Two Bases</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="nonlinearity-log-transforming-the-predictor.html"><a href="nonlinearity-log-transforming-the-predictor.html#base-e-logarithm-the-natural-logarithm"><i class="fa fa-check"></i><b>2.7</b> Base-<span class="math inline">\(e\)</span> Logarithm: The Natural Logarithm</a><ul>
<li class="chapter" data-level="2.7.1" data-path="nonlinearity-log-transforming-the-predictor.html"><a href="nonlinearity-log-transforming-the-predictor.html#using-the-natural-logarithm-in-a-regression-model"><i class="fa fa-check"></i><b>2.7.1</b> Using the Natural Logarithm in a Regression Model</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="nonlinearity-log-transforming-the-predictor.html"><a href="nonlinearity-log-transforming-the-predictor.html#including-covariates"><i class="fa fa-check"></i><b>2.8</b> Including Covariates</a><ul>
<li class="chapter" data-level="2.8.1" data-path="nonlinearity-log-transforming-the-predictor.html"><a href="nonlinearity-log-transforming-the-predictor.html#plot-of-the-model-results"><i class="fa fa-check"></i><b>2.8.1</b> Plot of the Model Results</a></li>
</ul></li>
<li class="chapter" data-level="2.9" data-path="nonlinearity-log-transforming-the-predictor.html"><a href="nonlinearity-log-transforming-the-predictor.html#polynomial-effects-vs.log-transformations"><i class="fa fa-check"></i><b>2.9</b> Polynomial Effects vs. Log-Transformations</a></li>
<li class="chapter" data-level="" data-path="nonlinearity-log-transforming-the-predictor.html"><a href="nonlinearity-log-transforming-the-predictor.html#other-resources-1"><i class="fa fa-check"></i>Other Resources</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="nonlinearity-log-transforming-the-outcome.html"><a href="nonlinearity-log-transforming-the-outcome.html"><i class="fa fa-check"></i><b>3</b> Nonlinearity: Log-Transforming the Outcome</a><ul>
<li class="chapter" data-level="" data-path="nonlinearity-log-transforming-the-outcome.html"><a href="nonlinearity-log-transforming-the-outcome.html#preparation-2"><i class="fa fa-check"></i>Preparation</a></li>
<li class="chapter" data-level="3.1" data-path="nonlinearity-log-transforming-the-outcome.html"><a href="nonlinearity-log-transforming-the-outcome.html#dataset-and-research-question-1"><i class="fa fa-check"></i><b>3.1</b> Dataset and Research Question</a></li>
<li class="chapter" data-level="3.2" data-path="nonlinearity-log-transforming-the-outcome.html"><a href="nonlinearity-log-transforming-the-outcome.html#examine-relationship-between-age-and-budget"><i class="fa fa-check"></i><b>3.2</b> Examine Relationship between Age and Budget</a></li>
<li class="chapter" data-level="3.3" data-path="nonlinearity-log-transforming-the-outcome.html"><a href="nonlinearity-log-transforming-the-outcome.html#transform-the-outcome-using-the-natural-logarithm-base-e"><i class="fa fa-check"></i><b>3.3</b> Transform the Outcome Using the Natural Logarithm (Base-e)</a></li>
<li class="chapter" data-level="3.4" data-path="nonlinearity-log-transforming-the-outcome.html"><a href="nonlinearity-log-transforming-the-outcome.html#re-analyze-using-the-log-transformed-budget"><i class="fa fa-check"></i><b>3.4</b> Re-analyze using the Log-Transformed Budget</a></li>
<li class="chapter" data-level="3.5" data-path="nonlinearity-log-transforming-the-outcome.html"><a href="nonlinearity-log-transforming-the-outcome.html#interpreting-the-regression-output"><i class="fa fa-check"></i><b>3.5</b> Interpreting the Regression Output</a><ul>
<li class="chapter" data-level="3.5.1" data-path="nonlinearity-log-transforming-the-outcome.html"><a href="nonlinearity-log-transforming-the-outcome.html#back-transforming-a-more-useful-interpretation"><i class="fa fa-check"></i><b>3.5.1</b> Back-Transforming: A More Useful Interpretation</a></li>
<li class="chapter" data-level="3.5.2" data-path="nonlinearity-log-transforming-the-outcome.html"><a href="nonlinearity-log-transforming-the-outcome.html#substituting-in-values-for-age-to-interpret-effects"><i class="fa fa-check"></i><b>3.5.2</b> Substituting in Values for Age to Interpret Effects</a></li>
<li class="chapter" data-level="3.5.3" data-path="nonlinearity-log-transforming-the-outcome.html"><a href="nonlinearity-log-transforming-the-outcome.html#approximate-interpretation-of-the-slope"><i class="fa fa-check"></i><b>3.5.3</b> Approximate Interpretation of the Slope</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="nonlinearity-log-transforming-the-outcome.html"><a href="nonlinearity-log-transforming-the-outcome.html#plotting-the-fitted-model-1"><i class="fa fa-check"></i><b>3.6</b> Plotting the Fitted Model</a></li>
<li class="chapter" data-level="3.7" data-path="nonlinearity-log-transforming-the-outcome.html"><a href="nonlinearity-log-transforming-the-outcome.html#relationship-between-mpaa-rating-and-budget"><i class="fa fa-check"></i><b>3.7</b> Relationship between MPAA Rating and Budget</a><ul>
<li class="chapter" data-level="3.7.1" data-path="nonlinearity-log-transforming-the-outcome.html"><a href="nonlinearity-log-transforming-the-outcome.html#regression-model"><i class="fa fa-check"></i><b>3.7.1</b> Regression Model</a></li>
<li class="chapter" data-level="3.7.2" data-path="nonlinearity-log-transforming-the-outcome.html"><a href="nonlinearity-log-transforming-the-outcome.html#mathematical-explanation-1"><i class="fa fa-check"></i><b>3.7.2</b> Mathematical Explanation</a></li>
<li class="chapter" data-level="3.7.3" data-path="nonlinearity-log-transforming-the-outcome.html"><a href="nonlinearity-log-transforming-the-outcome.html#approximate-interpretations"><i class="fa fa-check"></i><b>3.7.3</b> Approximate Interpretations</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="nonlinearity-log-transforming-the-outcome.html"><a href="nonlinearity-log-transforming-the-outcome.html#multiple-regression-main-effects-model"><i class="fa fa-check"></i><b>3.8</b> Multiple Regression: Main Effects Model</a><ul>
<li class="chapter" data-level="3.8.1" data-path="nonlinearity-log-transforming-the-outcome.html"><a href="nonlinearity-log-transforming-the-outcome.html#nested-f-test"><i class="fa fa-check"></i><b>3.8.1</b> Nested F-Test</a></li>
<li class="chapter" data-level="3.8.2" data-path="nonlinearity-log-transforming-the-outcome.html"><a href="nonlinearity-log-transforming-the-outcome.html#coefficient-level-interpretation"><i class="fa fa-check"></i><b>3.8.2</b> Coefficient-Level Interpretation</a></li>
<li class="chapter" data-level="3.8.3" data-path="nonlinearity-log-transforming-the-outcome.html"><a href="nonlinearity-log-transforming-the-outcome.html#plot-of-the-fitted-model"><i class="fa fa-check"></i><b>3.8.3</b> Plot of the Fitted Model</a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="nonlinearity-log-transforming-the-outcome.html"><a href="nonlinearity-log-transforming-the-outcome.html#multiple-regression-interaction-model"><i class="fa fa-check"></i><b>3.9</b> Multiple Regression: Interaction Model</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="log-transformations-some-final-thoughts.html"><a href="log-transformations-some-final-thoughts.html"><i class="fa fa-check"></i>Log Transformations: Some Final Thoughts</a><ul>
<li class="chapter" data-level="" data-path="log-transformations-some-final-thoughts.html"><a href="log-transformations-some-final-thoughts.html#power-transformations"><i class="fa fa-check"></i>Power Transformations</a><ul>
<li class="chapter" data-level="" data-path="log-transformations-some-final-thoughts.html"><a href="log-transformations-some-final-thoughts.html#ladder-of-transformations"><i class="fa fa-check"></i>Ladder of Transformations</a></li>
<li class="chapter" data-level="" data-path="log-transformations-some-final-thoughts.html"><a href="log-transformations-some-final-thoughts.html#rule-of-the-bulge"><i class="fa fa-check"></i>Rule of the Bulge</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="probability-distributions.html"><a href="probability-distributions.html"><i class="fa fa-check"></i><b>4</b> Probability Distributions</a><ul>
<li class="chapter" data-level="" data-path="probability-distributions.html"><a href="probability-distributions.html#preparation-3"><i class="fa fa-check"></i>Preparation</a></li>
<li class="chapter" data-level="4.1" data-path="probability-distributions.html"><a href="probability-distributions.html#dataset-and-research-question-2"><i class="fa fa-check"></i><b>4.1</b> Dataset and Research Question</a></li>
<li class="chapter" data-level="4.2" data-path="probability-distributions.html"><a href="probability-distributions.html#normal-distribution"><i class="fa fa-check"></i><b>4.2</b> Normal Distribution</a><ul>
<li class="chapter" data-level="4.2.1" data-path="probability-distributions.html"><a href="probability-distributions.html#other-useful-r-functions-for-working-with-probability-distributions"><i class="fa fa-check"></i><b>4.2.1</b> Other Useful R Functions for Working with Probability Distributions</a></li>
<li class="chapter" data-level="4.2.2" data-path="probability-distributions.html"><a href="probability-distributions.html#finding-cumulative-probability"><i class="fa fa-check"></i><b>4.2.2</b> Finding Cumulative Probability</a></li>
<li class="chapter" data-level="4.2.3" data-path="probability-distributions.html"><a href="probability-distributions.html#cumulative-density-and-p-value"><i class="fa fa-check"></i><b>4.2.3</b> Cumulative Density and <span class="math inline">\(p\)</span>-Value</a></li>
<li class="chapter" data-level="4.2.4" data-path="probability-distributions.html"><a href="probability-distributions.html#finding-quantiles"><i class="fa fa-check"></i><b>4.2.4</b> Finding Quantiles</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="probability-distributions.html"><a href="probability-distributions.html#students-t-distribution"><i class="fa fa-check"></i><b>4.3</b> Student’s <span class="math inline">\(t\)</span>-Distribution</a><ul>
<li class="chapter" data-level="4.3.1" data-path="probability-distributions.html"><a href="probability-distributions.html#comparing-probability-densities"><i class="fa fa-check"></i><b>4.3.1</b> Comparing Probability Densities</a></li>
<li class="chapter" data-level="4.3.2" data-path="probability-distributions.html"><a href="probability-distributions.html#comparing-cumulative-densities"><i class="fa fa-check"></i><b>4.3.2</b> Comparing Cumulative Densities</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="probability-distributions.html"><a href="probability-distributions.html#using-the-t-distribution-in-regression"><i class="fa fa-check"></i><b>4.4</b> Using the <span class="math inline">\(t\)</span>-Distribution in Regression</a></li>
<li class="chapter" data-level="4.5" data-path="probability-distributions.html"><a href="probability-distributions.html#model-level-inference-the-f-distribution"><i class="fa fa-check"></i><b>4.5</b> Model-Level Inference: The <span class="math inline">\(F\)</span>-Distribution</a><ul>
<li class="chapter" data-level="4.5.1" data-path="probability-distributions.html"><a href="probability-distributions.html#testing-the-model-level-null-hypothesis"><i class="fa fa-check"></i><b>4.5.1</b> Testing the Model-Level Null Hypothesis</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="probability-distributions.html"><a href="probability-distributions.html#mean-squares-are-variance-estimates"><i class="fa fa-check"></i><b>4.6</b> Mean Squares are Variance Estimates</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="maximum-likelihood-estimation.html"><a href="maximum-likelihood-estimation.html"><i class="fa fa-check"></i><b>5</b> Maximum Likelihood Estimation</a><ul>
<li class="chapter" data-level="" data-path="maximum-likelihood-estimation.html"><a href="maximum-likelihood-estimation.html#preparation-4"><i class="fa fa-check"></i>Preparation</a></li>
<li class="chapter" data-level="5.1" data-path="maximum-likelihood-estimation.html"><a href="maximum-likelihood-estimation.html#dataset-and-research-question-3"><i class="fa fa-check"></i><b>5.1</b> Dataset and Research Question</a></li>
<li class="chapter" data-level="5.2" data-path="maximum-likelihood-estimation.html"><a href="maximum-likelihood-estimation.html#joint-probability-density"><i class="fa fa-check"></i><b>5.2</b> Joint Probability Density</a></li>
<li class="chapter" data-level="5.3" data-path="maximum-likelihood-estimation.html"><a href="maximum-likelihood-estimation.html#likelihood"><i class="fa fa-check"></i><b>5.3</b> Likelihood</a></li>
<li class="chapter" data-level="5.4" data-path="maximum-likelihood-estimation.html"><a href="maximum-likelihood-estimation.html#maximum-likelihood"><i class="fa fa-check"></i><b>5.4</b> Maximum Likelihood</a><ul>
<li class="chapter" data-level="5.4.1" data-path="maximum-likelihood-estimation.html"><a href="maximum-likelihood-estimation.html#method-1-grid-search"><i class="fa fa-check"></i><b>5.4.1</b> Method 1: Grid Search</a></li>
<li class="chapter" data-level="5.4.2" data-path="maximum-likelihood-estimation.html"><a href="maximum-likelihood-estimation.html#log-likelihood"><i class="fa fa-check"></i><b>5.4.2</b> Log-Likelihood</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="maximum-likelihood-estimation.html"><a href="maximum-likelihood-estimation.html#maximum-likelihood-estimation-for-regression"><i class="fa fa-check"></i><b>5.5</b> Maximum Likelihood Estimation for Regression</a><ul>
<li class="chapter" data-level="5.5.1" data-path="maximum-likelihood-estimation.html"><a href="maximum-likelihood-estimation.html#large-search-spaces"><i class="fa fa-check"></i><b>5.5.1</b> Large Search Spaces</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="maximum-likelihood-estimation.html"><a href="maximum-likelihood-estimation.html#ml-estimation-in-regression-using-r"><i class="fa fa-check"></i><b>5.6</b> ML Estimation in Regression Using R</a><ul>
<li class="chapter" data-level="5.6.1" data-path="maximum-likelihood-estimation.html"><a href="maximum-likelihood-estimation.html#using-r-to-directly-compute-the-likelihood-and-log-likelihood"><i class="fa fa-check"></i><b>5.6.1</b> Using R to Directly Compute the Likelihood and Log-Likelihood</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="maximum-likelihood-estimation.html"><a href="maximum-likelihood-estimation.html#way-way-way-too-much-mathematics-way-too-much-math"><i class="fa fa-check"></i><b>5.7</b> Way, Way, Way too Much Mathematics {way-too-much-math}</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="data-codebook.html"><a href="data-codebook.html"><i class="fa fa-check"></i>Data Codebooks</a><ul>
<li class="chapter" data-level="" data-path="data-codebook.html"><a href="data-codebook.html#ed-schools"><i class="fa fa-check"></i>ed-schools.csv</a></li>
<li class="chapter" data-level="" data-path="data-codebook.html"><a href="data-codebook.html#mn-schools"><i class="fa fa-check"></i>mn-schools.csv</a></li>
<li class="chapter" data-level="" data-path="data-codebook.html"><a href="data-codebook.html#movies"><i class="fa fa-check"></i>movies.csv</a></li>
<li class="chapter" data-level="" data-path="data-codebook.html"><a href="data-codebook.html#riverview"><i class="fa fa-check"></i>riverview.csv</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">EPsy 8252 Notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="probability-distributions" class="section level1">
<h1><span class="header-section-number">Unit 4:</span> Probability Distributions</h1>
<p>In this set of notes, you will learn about common probability distributions.</p>
<hr />
<div id="preparation-3" class="section level3 unnumbered">
<h3>Preparation</h3>
<p>Before class you will need to do the following:</p>
<ul>
<li>Read Section 3.1.1: Probability Basics in Fox [Required Textbook]</li>
<li><p>Read Sections 3.3.1–3.3.4 (Continuous Distributions) in Fox [Required Textbook]</p></li>
<li><p>Refresh your knowledge about probability distributions by going though the <a href="https://www.khanacademy.org/math/probability/random-variables-topic">Kahn Academy: Random Variables and Probability Distributions</a> tutorial.</p></li>
</ul>
<p><br /></p>
<hr />
</div>
<div id="dataset-and-research-question-2" class="section level2">
<h2><span class="header-section-number">4.1</span> Dataset and Research Question</h2>
<p>In this set of notes, we will not be using a specific dataset.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Load libraries</span>
<span class="kw">library</span>(broom)
<span class="kw">library</span>(dplyr)
<span class="kw">library</span>(ggplot2)
<span class="kw">library</span>(readr)
<span class="kw">library</span>(sm)
<span class="kw">library</span>(tidyr)</code></pre></div>
</div>
<div id="normal-distribution" class="section level2">
<h2><span class="header-section-number">4.2</span> Normal Distribution</h2>
<p>The probability distribution of a normal distribution is mathematically defined as:</p>
<p><span class="math display">\[
p(x) = \frac{1}{\sigma\sqrt{2\pi}}\exp\left[-\frac{(x-\mu)^2}{2\sigma^2}\right]
\]</span></p>
<p>for <span class="math inline">\(-\infty \leq x \leq \infty\)</span>. Consider a normal distribution with a mean (<span class="math inline">\(\mu\)</span>) of 50, and a standard deviation (<span class="math inline">\(\sigma\)</span>) of 10. We can compute the probability density (<span class="math inline">\(p(x)\)</span>) for a particular <span class="math inline">\(x\)</span> value by using this equation. For example, the probability density for <span class="math inline">\(x=65\)</span> can be found using,</p>
<p><span class="math display">\[
p(65) = \frac{1}{10\sqrt{2\pi}}\exp\left[-\frac{(65-50)^2}{2\times10^2}\right] = 0.01295176
\]</span></p>
<p>Using R, we can carry out the computation,</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(<span class="dv">1</span> <span class="op">/</span><span class="st"> </span>(<span class="dv">10</span> <span class="op">*</span><span class="st"> </span><span class="kw">sqrt</span>(<span class="dv">2</span> <span class="op">*</span><span class="st"> </span>pi))) <span class="op">*</span><span class="st"> </span><span class="kw">exp</span>(<span class="op">-</span>(<span class="dv">225</span>) <span class="op">/</span><span class="st"> </span><span class="dv">200</span>)</code></pre></div>
<pre><code>[1] 0.01295</code></pre>
<p>There is also a more direct way to compute this using the <code>dnorm()</code> function. This function computes the density of <code>x</code> from a normal distribution with a specified <code>mean</code> and <code>sd</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">dnorm</span>(<span class="dt">x =</span> <span class="dv">65</span>, <span class="dt">mean =</span> <span class="dv">50</span>, <span class="dt">sd =</span> <span class="dv">10</span>)</code></pre></div>
<pre><code>[1] 0.01295</code></pre>
<p>If we compute the density for several <span class="math inline">\(x\)</span> values and plot them, we get the familiar normal shape; the graphical instantiation of the mathematical equation.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Create dataset</span>
fig_<span class="dv">01</span> =<span class="st"> </span><span class="kw">data.frame</span>(
  <span class="dt">X =</span> <span class="kw">seq</span>(<span class="dt">from =</span> <span class="dv">10</span>, <span class="dt">to =</span> <span class="dv">90</span>, <span class="dt">by =</span> <span class="fl">0.01</span>)
  ) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">rowwise</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(
    <span class="dt">Y =</span> <span class="kw">dnorm</span>(<span class="dt">x =</span> X, <span class="dt">mean =</span> <span class="dv">50</span>, <span class="dt">sd =</span> <span class="dv">10</span>)
    )

<span class="co"># Create plot</span>
<span class="kw">ggplot</span>(<span class="dt">data =</span> fig_<span class="dv">01</span>, <span class="kw">aes</span>(<span class="dt">x =</span> X, <span class="dt">y =</span> Y)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_bw</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">x =</span> <span class="dv">65</span>, <span class="dt">y =</span> <span class="fl">0.01295176</span>, <span class="dt">size =</span> <span class="dv">3</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-70"></span>
<img src="epsy-8252-notes_files/figure-html/unnamed-chunk-70-1.png" alt="Plot of the probability density function (PDF) for a Normal distribution with mean of 50 and standard deviation of 10. The density value for $x=65$, $p(65)= 0.01295176$, is also displayed on the PDF." width="50%" />
<p class="caption">
Figure 4.1: Plot of the probability density function (PDF) for a Normal distribution with mean of 50 and standard deviation of 10. The density value for <span class="math inline">\(x=65\)</span>, <span class="math inline">\(p(65)= 0.01295176\)</span>, is also displayed on the PDF.
</p>
</div>
<div id="other-useful-r-functions-for-working-with-probability-distributions" class="section level3">
<h3><span class="header-section-number">4.2.1</span> Other Useful R Functions for Working with Probability Distributions</h3>
<p>There are four primary functions for working with the normal probability distribution:</p>
<ul>
<li><code>dnorm()</code> : To compute the probability density (point on the curve)</li>
<li><code>pnorm()</code> : To compute the probability (area under the PDF)</li>
<li><code>qnorm()</code> : To compute the <span class="math inline">\(x\)</span> value given a particular probability</li>
<li><code>rnorm()</code> : To draw a random observation from the distribution</li>
</ul>
<p>Each of these requires the arguments <code>mean=</code> and <code>sd=</code>. Let’s look at some of them in use.</p>
</div>
<div id="finding-cumulative-probability" class="section level3">
<h3><span class="header-section-number">4.2.2</span> Finding Cumulative Probability</h3>
<p>The function <code>pnorm()</code> gives the probability <span class="math inline">\(x\)</span> is less than or equal to some quantile value in the distribution; the cumulative probability. For example, to find the probability that <span class="math inline">\(x \leq 65\)</span> we would use,</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">pnorm</span>(<span class="dt">q =</span> <span class="dv">65</span>, <span class="dt">mean =</span> <span class="dv">50</span>, <span class="dt">sd =</span> <span class="dv">10</span>)</code></pre></div>
<pre><code>[1] 0.9332</code></pre>
<p>This is akin to finding the proportion of the area under the normal PDF that is to the left of 65.</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-72"></span>
<img src="epsy-8252-notes_files/figure-html/unnamed-chunk-72-1.png" alt="Plot of the PDF for a normal distribution (M=50, SD=10) with the cumulative probability for X less than or equal to 65 shaded." width="50%" />
<p class="caption">
Figure 4.2: Plot of the PDF for a normal distribution (M=50, SD=10) with the cumulative probability for X less than or equal to 65 shaded.
</p>
</div>
<p>For the mathematically inclined, the grey-shaded area is expressed as an integral</p>
<p><span class="math display">\[
\int_{-\infty}^{65} p(x) dx
\]</span></p>
<p>where <span class="math inline">\(p(x)\)</span> is the PDF for the normal distribution.</p>
</div>
<div id="cumulative-density-and-p-value" class="section level3">
<h3><span class="header-section-number">4.2.3</span> Cumulative Density and <span class="math inline">\(p\)</span>-Value</h3>
<p>This type of computation is used most commonly to find a <span class="math inline">\(p\)</span>-value. The <span class="math inline">\(p\)</span>-value is just the area under the distribution (curve) that is AT LEAST as extreme as some observed value. Consider a hypothesis test of whether a population parameter is equal to 0. Also consider that we observed a statistic (that has been standardized) of <span class="math inline">\(z=2.5\)</span>. Then, the <span class="math inline">\(p\)</span>-value can be graphically displayed in the standard normal distribution as follows:</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-73"></span>
<img src="epsy-8252-notes_files/figure-html/unnamed-chunk-73-1.png" alt="Plot of the probability density function (PDF) for the standard normal distribution (M=0, SD=1). The cumulative density representing the p-value for a two-tailed test evaluating whether mu=0 using an observed z-value of 2.5 is also displayed." width="50%" />
<p class="caption">
Figure 4.3: Plot of the probability density function (PDF) for the standard normal distribution (M=0, SD=1). The cumulative density representing the p-value for a two-tailed test evaluating whether mu=0 using an observed z-value of 2.5 is also displayed.
</p>
</div>
<p>In most hypthesis tests, we test whether the parameter IS EQUAL to 0. Thus the values in the standard normal distribution more extreme than 2.5 encompass evidence against the hypothesis; those values greater than 2.5 and also those values less than <span class="math inline">\(-2.5\)</span>. (This is akin to testing a fair coin when both 8 heads OR 8 tails would provide evidence against fairness we have to consider evidence in both directions).</p>
<p>To compute this we use <code>pnorm()</code>. Remember, it computes the proportion of the area under the curve TO THE LEFT of a particular value. Here we will compute the are to the left of <span class="math inline">\(-2.5\)</span> and then double it to produce the actual <span class="math inline">\(p\)</span>-value.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="kw">pnorm</span>(<span class="dt">q =</span> <span class="op">-</span><span class="fl">2.5</span>, <span class="dt">mean =</span> <span class="dv">0</span>, <span class="dt">sd =</span> <span class="dv">1</span>)</code></pre></div>
<pre><code>[1] 0.01242</code></pre>
</div>
<div id="finding-quantiles" class="section level3">
<h3><span class="header-section-number">4.2.4</span> Finding Quantiles</h3>
<p>The <code>qnorm()</code> function is essentially the inverse of the <code>pnorm()</code> function. The <code>p</code> functions find the cumulative probability GIVEN a particular quantile. The <code>q</code> functions find the quantile GIVEN a cumulative probability. For example, in the normal distribution we defined earlier, half of the area is below the quantile value of 50 (the mean).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">qnorm</span>(<span class="dt">p =</span> <span class="fl">0.5</span>, <span class="dt">mean =</span> <span class="dv">50</span>, <span class="dt">sd =</span> <span class="dv">10</span>)</code></pre></div>
<pre><code>[1] 50</code></pre>
</div>
</div>
<div id="students-t-distribution" class="section level2">
<h2><span class="header-section-number">4.3</span> Student’s <span class="math inline">\(t\)</span>-Distribution</h2>
<p>Student’s <span class="math inline">\(t\)</span>-distribution looks like a standard normal distribution. In the figure below, Student’s <span class="math inline">\(t\)</span>-distribution is depicted with a solid, black line and the standard normal distribution (<span class="math inline">\(M=0\)</span>, <span class="math inline">\(SD=1\)</span>) is depicted with a dotted, red line.</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-76"></span>
<img src="epsy-8252-notes_files/figure-html/unnamed-chunk-76-1.png" alt="Plot of the probability density function (PDF) for the standard normal distribution (dotted, red line) and Student's t-distribution with 5 degrees of freedom (solid, black line)." width="50%" />
<p class="caption">
Figure 4.4: Plot of the probability density function (PDF) for the standard normal distribution (dotted, red line) and Student’s t-distribution with 5 degrees of freedom (solid, black line).
</p>
</div>
<p>Both the standard normal distribution and Student’s <span class="math inline">\(t\)</span>-distribution have a mean (expected value) of 0. The standard deviation for Student’s <span class="math inline">\(t\)</span>-distribution is larger than the standard deviation for the standard normal distribution (<span class="math inline">\(SD&gt;1\)</span>). You can see this in the distribution because the tails in Student’s <span class="math inline">\(t\)</span>-distribution are fatter (more error) than the standard normal distribution.</p>
<p>In practice, we often use Student’s <span class="math inline">\(t\)</span>-distribution rather than the standard normal distribution when we are using sample data to estimate the population. This estimation increases the error and thus is typically modeled using Student’s <span class="math inline">\(t\)</span>-distribution.</p>
<p>Student’s <span class="math inline">\(t\)</span>-distribution constitutes a family of distributions—not just a single distribution. The specific shape (and thus probability density) is defined by the <em>degrees of freedom</em>; <em>df</em>. The plot below shows the standard normal distribution (purple) and four <span class="math inline">\(t\)</span>-distributions with varying <em>df</em>-values.</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-77"></span>
<img src="epsy-8252-notes_files/figure-html/unnamed-chunk-77-1.png" alt="Plot of several t-distributions with differing degrees of freedom." width="80%" />
<p class="caption">
Figure 4.5: Plot of several t-distributions with differing degrees of freedom.
</p>
</div>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["df"],"name":[1],"type":["fctr"],"align":["left"]},{"label":["M"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["SD"],"name":[3],"type":["dbl"],"align":["right"]}],"data":[{"1":"03","2":"0","3":"2.00"},{"1":"05","2":"0","3":"1.50"},{"1":"10","2":"0","3":"1.22"},{"1":"25","2":"0","3":"1.08"},{"1":"z","2":"0","3":"1.00"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>If we compare the means and SDs for these distributions, we find that the mean for all the <span class="math inline">\(t\)</span>-distributions is 0, same as the standard normal distribution. All <span class="math inline">\(t\)</span>-distributions are unimodal and symmetric around zero. The SD for every <span class="math inline">\(t\)</span>-distribution is higher than the SD for the standrad normal distribution. Student <span class="math inline">\(t\)</span>-distributions with higher <em>df</em> values have less variation. It turns out that the standard normal distribution is a <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\(\infty\)</span> <em>df</em>. For the formula for the SD in a <span class="math inline">\(t\)</span>-distribution, see <span class="citation">Fox (<a href="#ref-Fox:2009">2009</a>)</span>.</p>
<p>There are four primary functions for working with Student’s <span class="math inline">\(t\)</span>-distribution:</p>
<ul>
<li><code>dt()</code> : To compute the probability density (point on the curve)</li>
<li><code>pt()</code> : To compute the probability (area under the PDF)</li>
<li><code>qt()</code> : To compute the <span class="math inline">\(x\)</span> value given a particular probability</li>
<li><code>rt()</code> : To draw a random observation from the distribution</li>
</ul>
<p>Each of these requires the arguments <code>df=</code>. Let’s look at some of them in use.</p>
<div id="comparing-probability-densities" class="section level3">
<h3><span class="header-section-number">4.3.1</span> Comparing Probability Densities</h3>
<p>How do the probability densities for a value of <span class="math inline">\(X\)</span> compare across these distributions? Let’s examine the <span class="math inline">\(X\)</span> value of 2.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Standard normal distribution</span>
<span class="kw">pnorm</span>(<span class="dt">q =</span> <span class="dv">2</span>, <span class="dt">mean =</span> <span class="dv">0</span>, <span class="dt">sd =</span> <span class="dv">1</span>)</code></pre></div>
<pre><code>[1] 0.9772</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># t-distribution with 3 df</span>
<span class="kw">pt</span>(<span class="dt">q =</span> <span class="dv">2</span>, <span class="dt">df =</span> <span class="dv">3</span>)</code></pre></div>
<pre><code>[1] 0.9303</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># t-distribution with 5 df</span>
<span class="kw">pt</span>(<span class="dt">q =</span> <span class="dv">2</span>, <span class="dt">df =</span> <span class="dv">5</span>)</code></pre></div>
<pre><code>[1] 0.949</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># t-distribution with 10 df</span>
<span class="kw">pt</span>(<span class="dt">q =</span> <span class="dv">2</span>, <span class="dt">df =</span> <span class="dv">10</span>)</code></pre></div>
<pre><code>[1] 0.9633</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># t-distribution with 25 df</span>
<span class="kw">pt</span>(<span class="dt">q =</span> <span class="dv">2</span>, <span class="dt">df =</span> <span class="dv">25</span>)</code></pre></div>
<pre><code>[1] 0.9718</code></pre>
<p>We are essentially comparing the height of these distributions at <span class="math inline">\(X=2\)</span>.</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-80"></span>
<img src="epsy-8252-notes_files/figure-html/unnamed-chunk-80-1.png" alt="Plot of several t-distributions with differing *degrees of freedom. The probability density for t=2 is also displayed for each of the distributions." width="80%" />
<p class="caption">
Figure 4.6: Plot of several t-distributions with differing *degrees of freedom. The probability density for t=2 is also displayed for each of the distributions.
</p>
</div>
</div>
<div id="comparing-cumulative-densities" class="section level3">
<h3><span class="header-section-number">4.3.2</span> Comparing Cumulative Densities</h3>
<p>What if we wanted to look at cumulative density? Consider out hypothesis test of whether a population parameter is equal to 0. ALso consider that we observed a statistic (that has been standardized) of 2.5 using a sample size of <span class="math inline">\(n=15\)</span>.</p>
<p>If we can assume that the SAMPLING DISTRIBUTION is normally-distributed then we can use the cumulative density in a normal distribution to compute a <span class="math inline">\(p\)</span>-value:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="kw">pnorm</span>(<span class="dt">q =</span> <span class="op">-</span><span class="fl">2.5</span>, <span class="dt">mean =</span> <span class="dv">0</span>, <span class="dt">sd =</span> <span class="dv">1</span>)</code></pre></div>
<pre><code>[1] 0.01242</code></pre>
<p>If, however, the SAMPLING DISTRIBUTION is <span class="math inline">\(t\)</span>-distributed then we need to use the cumulative density for a <span class="math inline">\(t\)</span>-distribution with the appropriate <em>df</em> to compute a <span class="math inline">\(p\)</span>-value. For example if we use <span class="math inline">\(df=n-1\)</span>, the two-tailed <span class="math inline">\(p\)</span>-value would be:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="kw">pt</span>(<span class="dt">q =</span> <span class="op">-</span><span class="fl">2.5</span>, <span class="dt">df =</span> <span class="dv">14</span>)</code></pre></div>
<pre><code>[1] 0.02547</code></pre>
<p>The <span class="math inline">\(p\)</span>-value using the <span class="math inline">\(t\)</span>-distribution is larger than the <span class="math inline">\(p\)</span>-value computed based on the standard normal distribution. This is again because of the increased error (uncertainty) we are introducing when we estimate from sample. This added uncertainty makes it harder for us to reject a hypothesis.</p>
</div>
</div>
<div id="using-the-t-distribution-in-regression" class="section level2">
<h2><span class="header-section-number">4.4</span> Using the <span class="math inline">\(t\)</span>-Distribution in Regression</h2>
<p>To illustrate how probability distributions are used in practice, we will will use the <em>riverside.csv</em> (see the <a href="#riverside">data codebook</a> here) and fit a regression model that uses education level and seniority to predict variation in employee income.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Read in data</span>
city =<span class="st"> </span><span class="kw">read_csv</span>(<span class="dt">file =</span> <span class="st">&quot;~/Documents/github/epsy-8252/data/riverside.csv&quot;</span>)
<span class="kw">head</span>(city)</code></pre></div>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["education"],"name":[1],"type":["dbl"],"align":["right"]},{"label":["income"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["seniority"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["gender"],"name":[4],"type":["chr"],"align":["left"]},{"label":["male"],"name":[5],"type":["dbl"],"align":["right"]},{"label":["party"],"name":[6],"type":["chr"],"align":["left"]}],"data":[{"1":"8","2":"37449","3":"7","4":"male","5":"1","6":"Democrat"},{"1":"8","2":"26430","3":"9","4":"female","5":"0","6":"Independent"},{"1":"10","2":"47034","3":"14","4":"male","5":"1","6":"Democrat"},{"1":"10","2":"34182","3":"16","4":"female","5":"0","6":"Independent"},{"1":"10","2":"25479","3":"1","4":"female","5":"0","6":"Republican"},{"1":"12","2":"46488","3":"11","4":"female","5":"0","6":"Democrat"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Fit regression model</span>
lm.<span class="dv">1</span> =<span class="st"> </span><span class="kw">lm</span>(income <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>education <span class="op">+</span><span class="st"> </span>seniority, <span class="dt">data =</span> city)

<span class="co"># Coefficient-level output</span>
<span class="kw">tidy</span>(lm.<span class="dv">1</span>)</code></pre></div>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["term"],"name":[1],"type":["chr"],"align":["left"]},{"label":["estimate"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["std.error"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["statistic"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["p.value"],"name":[5],"type":["dbl"],"align":["right"]}],"data":[{"1":"(Intercept)","2":"6769.2","3":"5372.9","4":"1.260","5":"0.2177593429"},{"1":"education","2":"2251.8","3":"334.6","4":"6.729","5":"0.0000002203"},{"1":"seniority","2":"738.8","3":"210.1","4":"3.516","5":"0.0014597774"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>How do we obtain the <span class="math inline">\(p\)</span>-value for each of the coefficients? Recall that the coefficients and SEs for the coefficients are computed directly from the raw data. Then we can compute a test-statistic by dividing the coefficient estimate by the SE. For example, to compute the test-statistic associated with education level:</p>
<p><span class="math display">\[
t = \frac{2252}{335} = 6.72
\]</span></p>
<p>Since we are estimating the SE using sample data, our test statistic is likely <span class="math inline">\(t\)</span>-distributed. Which value should we use for <em>df</em>? Well, for that, statistical theory tells us that we should use the error <em>df</em> value. In our data,</p>
<p><span class="math display">\[
\begin{split}
n &amp;= 32 \\
\mathrm{Total~df} &amp;= 32-1 = 31\\
\mathrm{Model~df} &amp;= 2~\mathrm{(two~predictors)} \\
\mathrm{Error~df} &amp;= 31-2 = 29
\end{split}
\]</span></p>
<p>Using the <span class="math inline">\(t\)</span>-distribution with 29 <em>df</em>,</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="kw">pt</span>(<span class="dt">q =</span> <span class="op">-</span><span class="fl">6.72</span>, <span class="dt">df =</span> <span class="dv">29</span>)</code></pre></div>
<pre><code>[1] 0.0000002257</code></pre>
<p>For seniority (and the intercept), we would use the same <span class="math inline">\(t\)</span>-distribution, but our test statistic would differ:</p>
<p><span class="math display">\[
\begin{split}
t_{\mathrm{Intercept}} &amp;= \frac{6769}{5373} = 1.26 \\
t_{\mathrm{Seniority}} &amp;= \frac{739}{210} = 3.52 \\
\end{split}
\]</span></p>
<p>The associated <span class="math inline">\(p\)</span>-values are:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Intercept p-value</span>
<span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="kw">pt</span>(<span class="dt">q =</span> <span class="op">-</span><span class="fl">1.26</span>, <span class="dt">df =</span> <span class="dv">29</span>)</code></pre></div>
<pre><code>[1] 0.2177</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Seniority p-value</span>
<span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="kw">pt</span>(<span class="dt">q =</span> <span class="op">-</span><span class="fl">3.52</span>, <span class="dt">df =</span> <span class="dv">29</span>)</code></pre></div>
<pre><code>[1] 0.001446</code></pre>
</div>
<div id="model-level-inference-the-f-distribution" class="section level2">
<h2><span class="header-section-number">4.5</span> Model-Level Inference: The <span class="math inline">\(F\)</span>-Distribution</h2>
<p>The model-level inference for regression is based on an <span class="math inline">\(F\)</span>-statistic, which is a standardized measure of <span class="math inline">\(R^2\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Model-level output</span>
<span class="kw">glance</span>(lm.<span class="dv">1</span>)</code></pre></div>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["r.squared"],"name":[1],"type":["dbl"],"align":["right"]},{"label":["adj.r.squared"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["sigma"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["statistic"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["p.value"],"name":[5],"type":["dbl"],"align":["right"]},{"label":["df"],"name":[6],"type":["int"],"align":["right"]},{"label":["logLik"],"name":[7],"type":["dbl"],"align":["right"]},{"label":["AIC"],"name":[8],"type":["dbl"],"align":["right"]},{"label":["BIC"],"name":[9],"type":["dbl"],"align":["right"]},{"label":["deviance"],"name":[10],"type":["dbl"],"align":["right"]},{"label":["df.residual"],"name":[11],"type":["int"],"align":["right"]}],"data":[{"1":"0.7418","2":"0.724","3":"7646","4":"41.65","5":"0.000000002977","6":"3","7":"-330","8":"667.9","9":"673.8","10":"1695313285","11":"29","_rn_":"1"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>In this example, the sample <span class="math inline">\(R^2\)</span> value is 0.742. Computation of the <span class="math inline">\(F\)</span>-statistic relies on two <em>df</em> values—the model degrees of freedom (2) and the error degrees of freedom (29). To compute the <span class="math inline">\(F\)</span>-statistics from <span class="math inline">\(R^2\)</span> we use:</p>
<p><span class="math display">\[
F = \frac{R^2}{1-R^2} \times \frac{\mathrm{df}_{\mathrm{Error}}}{\mathrm{df}_{\mathrm{Model}}}
\]</span></p>
<p>In our example, we compute <span class="math inline">\(F\)</span> as:</p>
<p><span class="math display">\[
\begin{split}
F &amp;= \frac{0.742}{1-0.742} \times \frac{29}{2} \\
&amp;= 41.7
\end{split}
\]</span></p>
<p>We write this standardization of <span class="math inline">\(R^2\)</span> as <span class="math inline">\(F(2,29)=41.7\)</span>.</p>
<div id="testing-the-model-level-null-hypothesis" class="section level3">
<h3><span class="header-section-number">4.5.1</span> Testing the Model-Level Null Hypothesis</h3>
<p>It is often worth testing whether the model explains a statistically significant amount of variation in the population. To do this we test the null hypothesis:</p>
<p><span class="math display">\[
H_0:\rho^2 = 0
\]</span></p>
<p>Similar to the tests of the coefficients, we evaluate our test statistic (<span class="math inline">\(F\)</span> in this case) in the appropriate test distribution, in this case an <span class="math inline">\(F\)</span>-distribution with 2 and 29 degrees of freedom. (The shape of the <span class="math inline">\(F\)</span>-distribution is based on two <em>df</em> values.) The figure below, shows the <span class="math inline">\(F(2,29)\)</span>-distribution as a solid, black line.</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-87"></span>
<img src="epsy-8252-notes_files/figure-html/unnamed-chunk-87-1.png" alt="Plot of several F-distributions with differing degrees of freedom. The F(2,29)-distribution is shown as a solid, black line." width="80%" />
<p class="caption">
Figure 4.7: Plot of several F-distributions with differing degrees of freedom. The F(2,29)-distribution is shown as a solid, black line.
</p>
</div>
<p>The <span class="math inline">\(F\)</span>-distribution, like the <span class="math inline">\(t\)</span>-distribution is a family of distributions. They are positively skewed and generally have a lower-limit of 0. Because of this, when we use the <span class="math inline">\(F\)</span>-distribution to compute a <span class="math inline">\(p\)</span>-value, we only compute the cumulative density GREATER THAN OR EQUAL TO the value of the standradized test statistic.</p>
<div id="computing-f-from-the-anova-partitioning" class="section level4">
<h4><span class="header-section-number">4.5.1.1</span> Computing F from the ANOVA Partitioning</h4>
<p>We can also compute the model-level <span class="math inline">\(F\)</span>-statistic using the partititioning of variation from the ANOVA table.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">anova</span>(lm.<span class="dv">1</span>)</code></pre></div>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["Df"],"name":[1],"type":["int"],"align":["right"]},{"label":["Sum Sq"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["Mean Sq"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["F value"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["Pr(>F)"],"name":[5],"type":["dbl"],"align":["right"]}],"data":[{"1":"1","2":"4147330492","3":"4147330492","4":"70.94","5":"0.000000002781","_rn_":"education"},{"1":"1","2":"722883649","3":"722883649","4":"12.37","5":"0.001459777426","_rn_":"seniority"},{"1":"29","2":"1695313285","3":"58459079","4":"NA","5":"NA","_rn_":"Residuals"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>The <span class="math inline">\(F\)</span>-statistic is a ratio of the mean square for the model and the mean square for the error. To compute a mean square we use the general computation</p>
<p><span class="math display">\[
\mathrm{MS} = \frac{\mathrm{SS}}{\mathrm{df}}
\]</span></p>
<p>The model includes both the education and seniority predictor, so we combine the SS and df. The MS model is:</p>
<p><span class="math display">\[
\begin{split}
\mathrm{MS}_{\mathrm{Model}} &amp;= \frac{\mathrm{SS}_{\mathrm{Model}}}{\mathrm{df}_{\mathrm{Model}}} \\
&amp;= \frac{4147330492 + 722883649}{1 + 1} \\
&amp;= \frac{4870214141}{2} \\
&amp;= 2435107070
\end{split}
\]</span></p>
<p>The MS error is:</p>
<p><span class="math display">\[
\begin{split}
\mathrm{MS}_{\mathrm{Error}} &amp;= \frac{\mathrm{SS}_{\mathrm{Error}}}{\mathrm{df}_{\mathrm{Error}}} \\
&amp;= \frac{1695313285 }{29} \\
&amp;= 58459079
\end{split}
\]</span></p>
<p>Then, we compute the <span class="math inline">\(F\)</span>-statistic by computing the ratio of these two mean squares.</p>
<p><span class="math display">\[
\begin{split}
F &amp;= \frac{\mathrm{MS}_{\mathrm{Model}}}{\mathrm{MS}_{\mathrm{Error}}} \\
&amp;= \frac{2435107070}{58459079} \\
&amp;= 41.7
\end{split}
\]</span></p>
<p>This is the observed <span class="math inline">\(F\)</span>-statistic for the model. Note that this is an identical computation (although reframed) as the initial computation for <span class="math inline">\(F\)</span>.</p>
$$
<span class="math display">\[\begin{split}
F &amp;= \frac{R^2}{1-R^2} \times \frac{\mathrm{df}_{\mathrm{Error}}}{\mathrm{df}_{\mathrm{Model}}} \\[1em]
&amp;= \frac{\frac{\mathrm{SS}_{\mathrm{Model}}}{\mathrm{SS}_{\mathrm{Total}}}}{\frac{\mathrm{SS}_{\mathrm{Error}}}{\mathrm{SS}_{\mathrm{Total}}}} \times \frac{\mathrm{df}_{\mathrm{Error}}}{\mathrm{df}_{\mathrm{Model}}} \\[1em]
&amp;= \frac{\mathrm{SS}_{\mathrm{Model}}}{\mathrm{SS}_{\mathrm{Error}}} \times \frac{\mathrm{df}_{\mathrm{Error}}}{\mathrm{df}_{\mathrm{Model}}} \\[1em]
&amp;= \frac{\mathrm{SS}_{\mathrm{Model}}}{\mathrm{df}_{\mathrm{Model}}} \times \frac{\mathrm{df}_{\mathrm{Error}}}{\mathrm{SS}_{\mathrm{Error}}} \\[1em]

&amp;= \mathrm{MS}_{\mathrm{Model}} \times \frac{1}{\mathrm{MS}_{\mathrm{Error}}}\\[1em]
&amp;= \frac{\mathrm{MS}_{\mathrm{Model}}}{\mathrm{MS}_{\mathrm{Error}}}
\end{split}\]</span>
<p>$$</p>
<p>To test the null hypothesis, <span class="math inline">\(H_0:\rho^2=0\)</span>, we evaluate this observed <span class="math inline">\(F\)</span>-statistic in an <span class="math inline">\(F\)</span>-distribution with the 2 and 29 degrees of freedom.</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-89"></span>
<img src="epsy-8252-notes_files/figure-html/unnamed-chunk-89-1.png" alt="Plot of the probability density function (PDF) for the F-distribution with 2 and 29 degrees of freedom. The cumulative density representing the p-value for a two-tailed test evaluating whether rho-squared=0 using an observed F-statistic of 41.7 is also displayed." width="80%" />
<p class="caption">
Figure 4.8: Plot of the probability density function (PDF) for the F-distribution with 2 and 29 degrees of freedom. The cumulative density representing the p-value for a two-tailed test evaluating whether rho-squared=0 using an observed F-statistic of 41.7 is also displayed.
</p>
</div>
<p>The computation using the cumulative density function, <code>pf()</code>, to obtain the <span class="math inline">\(p\)</span>-value is:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">pf</span>(<span class="fl">41.7</span>, <span class="dt">df1 =</span> <span class="dv">2</span>, <span class="dt">df2 =</span> <span class="dv">29</span>)</code></pre></div>
<pre><code>[1] 0.000000002942</code></pre>
</div>
</div>
</div>
<div id="mean-squares-are-variance-estimates" class="section level2">
<h2><span class="header-section-number">4.6</span> Mean Squares are Variance Estimates</h2>
<p>Mean squares are estimates of the variance. Consider the computational formula for the sample variance,</p>
<p><span class="math display">\[
\hat{\sigma}^2 = \frac{\sum(Y - \bar{Y})^2}{n-1}
\]</span></p>
<p>This is the total sum of squares divided by the total <em>df</em>. When we compute an <span class="math inline">\(F\)</span>-statistic, we are finding the ratio of two different variance estimates—one based on the model (explained variance) and one based on the error (unexplained variance). Under the null hypothesis that <span class="math inline">\(\rho^2 = 0\)</span>, we are assuming that all the variance is unexplained. In that case, our <span class="math inline">\(F\)</span>-statistic would be close to zero. When the model explains asignificant amount of variation, the numerator gets larger relative to the denominator and the <span class="math inline">\(F\)</span>-value is larger.</p>
<p>The mean squared error (from the <code>anova()</code> output) plays a special role in regression analysis. It is the variance estimate for the conditional distributions of the residuals in our visual depiction of the distributional assumptions of the residuals underlying linear regression.</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-91"></span>
<img src="images/regression-assumptions-residuals.png" alt="Visual depiction of the distributional assumptions of the residuals underlying linear regression." width="70%" />
<p class="caption">
Figure 4.9: Visual depiction of the distributional assumptions of the residuals underlying linear regression.
</p>
</div>
<p>Recall that we made implicit assumptions about the conditional distributions of the residuals, namely that they were identically and normally distributed with a mean of zero and some variance. Based on the estimate of the mean squared error, the variance of each of these distributions is 58,459,079.</p>
<p>While the variance is a mathematical convenience, the standard deviation is a better descriptor of the variation in these distributions. The standard deviation is 7646.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sqrt</span>(<span class="dv">58459079</span>)</code></pre></div>
<pre><code>[1] 7646</code></pre>
<p>We can also obtain this value from the model-level regression output. Here it is typically referred to as the <em>Root Mean Squared Error</em> (RMSE). In the <code>glance()</code> output this value is in the <code>sigma</code> column.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">glance</span>(lm.<span class="dv">1</span>)</code></pre></div>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["r.squared"],"name":[1],"type":["dbl"],"align":["right"]},{"label":["adj.r.squared"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["sigma"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["statistic"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["p.value"],"name":[5],"type":["dbl"],"align":["right"]},{"label":["df"],"name":[6],"type":["int"],"align":["right"]},{"label":["logLik"],"name":[7],"type":["dbl"],"align":["right"]},{"label":["AIC"],"name":[8],"type":["dbl"],"align":["right"]},{"label":["BIC"],"name":[9],"type":["dbl"],"align":["right"]},{"label":["deviance"],"name":[10],"type":["dbl"],"align":["right"]},{"label":["df.residual"],"name":[11],"type":["int"],"align":["right"]}],"data":[{"1":"0.7418","2":"0.724","3":"7646","4":"41.65","5":"0.000000002977","6":"3","7":"-330","8":"667.9","9":"673.8","10":"1695313285","11":"29","_rn_":"1"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>Why is this value important? It gives the expected variation in the distribution. For example, since all of the conditional distributions of the residuals are normally distribued, we would expect that 95% of the residuals would fall between <span class="math inline">\(\pm2\)</span> standard errors from 0; or, in this case, between <span class="math inline">\(-15292\)</span> and 15292. Observations with residuals that are more extreme may be regression outliers.</p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-Fox:2009">
<p>Fox, J. (2009). <em>A mathematical primer for social statistics</em>. Thousand Oaks, CA: Sage.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="log-transformations-some-final-thoughts.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="maximum-likelihood-estimation.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": {},
"instapper": false
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
},
"collapse": "section",
"toolbar": null,
"position": "fixed",
"search": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
