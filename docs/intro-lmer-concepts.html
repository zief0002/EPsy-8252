<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Unit 8: Introduction to Mixed-Effects Models: Conceptual Ideas | EPsy 8252 Notes</title>
  <meta name="description" content="These are the notes for EPsy 8252.">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="Unit 8: Introduction to Mixed-Effects Models: Conceptual Ideas | EPsy 8252 Notes" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="These are the notes for EPsy 8252." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Unit 8: Introduction to Mixed-Effects Models: Conceptual Ideas | EPsy 8252 Notes" />
  
  <meta name="twitter:description" content="These are the notes for EPsy 8252." />
  

<meta name="author" content="Andrew Zieffler">


<meta name="date" content="2019-01-22">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="moreinfocrit.html">
<link rel="next" href="intro-lmer-fitting.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<link href="libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet" />
<script src="libs/pagedtable-1.1/js/pagedtable.js"></script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
<link rel="stylesheet" href="print.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">EPsy 8252 Notes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction to the Course</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#course-content"><i class="fa fa-check"></i>Course Content</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#books-and-other-reading-materials"><i class="fa fa-check"></i>Books and Other Reading Materials</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#prerequisites"><i class="fa fa-check"></i>Prerequisites</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="rmarkdown.html"><a href="rmarkdown.html"><i class="fa fa-check"></i><b>1</b> R Markdown</a><ul>
<li class="chapter" data-level="" data-path="rmarkdown.html"><a href="rmarkdown.html#preparation"><i class="fa fa-check"></i>Preparation</a></li>
<li class="chapter" data-level="" data-path="rmarkdown.html"><a href="rmarkdown.html#notes"><i class="fa fa-check"></i>Notes</a></li>
<li class="chapter" data-level="" data-path="rmarkdown.html"><a href="rmarkdown.html#other-resources"><i class="fa fa-check"></i>Other Resources</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="pretty-printing-tables-in-markdown.html"><a href="pretty-printing-tables-in-markdown.html"><i class="fa fa-check"></i>Pretty-Printing Tables in Markdown</a><ul>
<li class="chapter" data-level="1.1" data-path="pretty-printing-tables-in-markdown.html"><a href="pretty-printing-tables-in-markdown.html#summary-statistics-table"><i class="fa fa-check"></i><b>1.1</b> Summary Statistics Table</a></li>
<li class="chapter" data-level="1.2" data-path="pretty-printing-tables-in-markdown.html"><a href="pretty-printing-tables-in-markdown.html#correlation-table"><i class="fa fa-check"></i><b>1.2</b> Correlation Table</a></li>
<li class="chapter" data-level="1.3" data-path="pretty-printing-tables-in-markdown.html"><a href="pretty-printing-tables-in-markdown.html#regression-table"><i class="fa fa-check"></i><b>1.3</b> Regression Table</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="nonlinearity-log-transforming-the-predictor.html"><a href="nonlinearity-log-transforming-the-predictor.html"><i class="fa fa-check"></i><b>2</b> Nonlinearity: Log-Transforming the Predictor</a><ul>
<li class="chapter" data-level="" data-path="nonlinearity-log-transforming-the-predictor.html"><a href="nonlinearity-log-transforming-the-predictor.html#preparation-1"><i class="fa fa-check"></i>Preparation</a></li>
<li class="chapter" data-level="2.1" data-path="nonlinearity-log-transforming-the-predictor.html"><a href="nonlinearity-log-transforming-the-predictor.html#dataset-and-research-question"><i class="fa fa-check"></i><b>2.1</b> Dataset and Research Question</a></li>
<li class="chapter" data-level="2.2" data-path="nonlinearity-log-transforming-the-predictor.html"><a href="nonlinearity-log-transforming-the-predictor.html#log-transformation-of-a-variable"><i class="fa fa-check"></i><b>2.2</b> Log-Transformation of a Variable</a><ul>
<li class="chapter" data-level="2.2.1" data-path="nonlinearity-log-transforming-the-predictor.html"><a href="nonlinearity-log-transforming-the-predictor.html#quick-refresher-on-logarithms"><i class="fa fa-check"></i><b>2.2.1</b> Quick Refresher on Logarithms</a></li>
<li class="chapter" data-level="2.2.2" data-path="nonlinearity-log-transforming-the-predictor.html"><a href="nonlinearity-log-transforming-the-predictor.html#log-transforming-variables"><i class="fa fa-check"></i><b>2.2.2</b> Log-Transforming Variables</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="nonlinearity-log-transforming-the-predictor.html"><a href="nonlinearity-log-transforming-the-predictor.html#fitting-the-regression-model"><i class="fa fa-check"></i><b>2.3</b> Fitting the Regression Model</a><ul>
<li class="chapter" data-level="2.3.1" data-path="nonlinearity-log-transforming-the-predictor.html"><a href="nonlinearity-log-transforming-the-predictor.html#examine-the-assumption-of-linearity"><i class="fa fa-check"></i><b>2.3.1</b> Examine the Assumption of Linearity</a></li>
<li class="chapter" data-level="2.3.2" data-path="nonlinearity-log-transforming-the-predictor.html"><a href="nonlinearity-log-transforming-the-predictor.html#interpret-the-regression-results"><i class="fa fa-check"></i><b>2.3.2</b> Interpret the Regression Results</a></li>
<li class="chapter" data-level="2.3.3" data-path="nonlinearity-log-transforming-the-predictor.html"><a href="nonlinearity-log-transforming-the-predictor.html#better-interpretations-back-transforming"><i class="fa fa-check"></i><b>2.3.3</b> Better Interpretations: Back-transforming</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="nonlinearity-log-transforming-the-predictor.html"><a href="nonlinearity-log-transforming-the-predictor.html#alternative-method-of-fitting-the-model"><i class="fa fa-check"></i><b>2.4</b> Alternative Method of Fitting the Model</a></li>
<li class="chapter" data-level="2.5" data-path="nonlinearity-log-transforming-the-predictor.html"><a href="nonlinearity-log-transforming-the-predictor.html#plotting-the-fitted-model"><i class="fa fa-check"></i><b>2.5</b> Plotting the Fitted Model</a></li>
<li class="chapter" data-level="2.6" data-path="nonlinearity-log-transforming-the-predictor.html"><a href="nonlinearity-log-transforming-the-predictor.html#different-base-values-in-the-logarithm"><i class="fa fa-check"></i><b>2.6</b> Different Base Values in the Logarithm</a><ul>
<li class="chapter" data-level="2.6.1" data-path="nonlinearity-log-transforming-the-predictor.html"><a href="nonlinearity-log-transforming-the-predictor.html#comparing-the-output-from-the-two-bases"><i class="fa fa-check"></i><b>2.6.1</b> Comparing the Output from the Two Bases</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="nonlinearity-log-transforming-the-predictor.html"><a href="nonlinearity-log-transforming-the-predictor.html#base-e-logarithm-the-natural-logarithm"><i class="fa fa-check"></i><b>2.7</b> Base-<span class="math inline">\(e\)</span> Logarithm: The Natural Logarithm</a><ul>
<li class="chapter" data-level="2.7.1" data-path="nonlinearity-log-transforming-the-predictor.html"><a href="nonlinearity-log-transforming-the-predictor.html#using-the-natural-logarithm-in-a-regression-model"><i class="fa fa-check"></i><b>2.7.1</b> Using the Natural Logarithm in a Regression Model</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="nonlinearity-log-transforming-the-predictor.html"><a href="nonlinearity-log-transforming-the-predictor.html#including-covariates"><i class="fa fa-check"></i><b>2.8</b> Including Covariates</a><ul>
<li class="chapter" data-level="2.8.1" data-path="nonlinearity-log-transforming-the-predictor.html"><a href="nonlinearity-log-transforming-the-predictor.html#plot-of-the-model-results"><i class="fa fa-check"></i><b>2.8.1</b> Plot of the Model Results</a></li>
</ul></li>
<li class="chapter" data-level="2.9" data-path="nonlinearity-log-transforming-the-predictor.html"><a href="nonlinearity-log-transforming-the-predictor.html#polynomial-effects-vs.-log-transformations"><i class="fa fa-check"></i><b>2.9</b> Polynomial Effects vs. Log-Transformations</a></li>
<li class="chapter" data-level="" data-path="nonlinearity-log-transforming-the-predictor.html"><a href="nonlinearity-log-transforming-the-predictor.html#other-resources-1"><i class="fa fa-check"></i>Other Resources</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="nonlinearity-log-transforming-the-outcome.html"><a href="nonlinearity-log-transforming-the-outcome.html"><i class="fa fa-check"></i><b>3</b> Nonlinearity: Log-Transforming the Outcome</a><ul>
<li class="chapter" data-level="" data-path="nonlinearity-log-transforming-the-outcome.html"><a href="nonlinearity-log-transforming-the-outcome.html#preparation-2"><i class="fa fa-check"></i>Preparation</a></li>
<li class="chapter" data-level="3.1" data-path="nonlinearity-log-transforming-the-outcome.html"><a href="nonlinearity-log-transforming-the-outcome.html#dataset-and-research-question-1"><i class="fa fa-check"></i><b>3.1</b> Dataset and Research Question</a></li>
<li class="chapter" data-level="3.2" data-path="nonlinearity-log-transforming-the-outcome.html"><a href="nonlinearity-log-transforming-the-outcome.html#examine-relationship-between-age-and-budget"><i class="fa fa-check"></i><b>3.2</b> Examine Relationship between Age and Budget</a></li>
<li class="chapter" data-level="3.3" data-path="nonlinearity-log-transforming-the-outcome.html"><a href="nonlinearity-log-transforming-the-outcome.html#transform-the-outcome-using-the-natural-logarithm-base-e"><i class="fa fa-check"></i><b>3.3</b> Transform the Outcome Using the Natural Logarithm (Base-e)</a></li>
<li class="chapter" data-level="3.4" data-path="nonlinearity-log-transforming-the-outcome.html"><a href="nonlinearity-log-transforming-the-outcome.html#re-analyze-using-the-log-transformed-budget"><i class="fa fa-check"></i><b>3.4</b> Re-analyze using the Log-Transformed Budget</a></li>
<li class="chapter" data-level="3.5" data-path="nonlinearity-log-transforming-the-outcome.html"><a href="nonlinearity-log-transforming-the-outcome.html#interpreting-the-regression-output"><i class="fa fa-check"></i><b>3.5</b> Interpreting the Regression Output</a><ul>
<li class="chapter" data-level="3.5.1" data-path="nonlinearity-log-transforming-the-outcome.html"><a href="nonlinearity-log-transforming-the-outcome.html#back-transforming-a-more-useful-interpretation"><i class="fa fa-check"></i><b>3.5.1</b> Back-Transforming: A More Useful Interpretation</a></li>
<li class="chapter" data-level="3.5.2" data-path="nonlinearity-log-transforming-the-outcome.html"><a href="nonlinearity-log-transforming-the-outcome.html#substituting-in-values-for-age-to-interpret-effects"><i class="fa fa-check"></i><b>3.5.2</b> Substituting in Values for Age to Interpret Effects</a></li>
<li class="chapter" data-level="3.5.3" data-path="nonlinearity-log-transforming-the-outcome.html"><a href="nonlinearity-log-transforming-the-outcome.html#approximate-interpretation-of-the-slope"><i class="fa fa-check"></i><b>3.5.3</b> Approximate Interpretation of the Slope</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="nonlinearity-log-transforming-the-outcome.html"><a href="nonlinearity-log-transforming-the-outcome.html#plotting-the-fitted-model-1"><i class="fa fa-check"></i><b>3.6</b> Plotting the Fitted Model</a></li>
<li class="chapter" data-level="3.7" data-path="nonlinearity-log-transforming-the-outcome.html"><a href="nonlinearity-log-transforming-the-outcome.html#relationship-between-mpaa-rating-and-budget"><i class="fa fa-check"></i><b>3.7</b> Relationship between MPAA Rating and Budget</a><ul>
<li class="chapter" data-level="3.7.1" data-path="nonlinearity-log-transforming-the-outcome.html"><a href="nonlinearity-log-transforming-the-outcome.html#regression-model"><i class="fa fa-check"></i><b>3.7.1</b> Regression Model</a></li>
<li class="chapter" data-level="3.7.2" data-path="nonlinearity-log-transforming-the-outcome.html"><a href="nonlinearity-log-transforming-the-outcome.html#mathematical-explanation-1"><i class="fa fa-check"></i><b>3.7.2</b> Mathematical Explanation</a></li>
<li class="chapter" data-level="3.7.3" data-path="nonlinearity-log-transforming-the-outcome.html"><a href="nonlinearity-log-transforming-the-outcome.html#approximate-interpretations"><i class="fa fa-check"></i><b>3.7.3</b> Approximate Interpretations</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="nonlinearity-log-transforming-the-outcome.html"><a href="nonlinearity-log-transforming-the-outcome.html#multiple-regression-main-effects-model"><i class="fa fa-check"></i><b>3.8</b> Multiple Regression: Main Effects Model</a><ul>
<li class="chapter" data-level="3.8.1" data-path="nonlinearity-log-transforming-the-outcome.html"><a href="nonlinearity-log-transforming-the-outcome.html#nested-f-test"><i class="fa fa-check"></i><b>3.8.1</b> Nested F-Test</a></li>
<li class="chapter" data-level="3.8.2" data-path="nonlinearity-log-transforming-the-outcome.html"><a href="nonlinearity-log-transforming-the-outcome.html#coefficient-level-interpretation"><i class="fa fa-check"></i><b>3.8.2</b> Coefficient-Level Interpretation</a></li>
<li class="chapter" data-level="3.8.3" data-path="nonlinearity-log-transforming-the-outcome.html"><a href="nonlinearity-log-transforming-the-outcome.html#plot-of-the-fitted-model"><i class="fa fa-check"></i><b>3.8.3</b> Plot of the Fitted Model</a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="nonlinearity-log-transforming-the-outcome.html"><a href="nonlinearity-log-transforming-the-outcome.html#multiple-regression-interaction-model"><i class="fa fa-check"></i><b>3.9</b> Multiple Regression: Interaction Model</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="log-transformations-some-final-thoughts.html"><a href="log-transformations-some-final-thoughts.html"><i class="fa fa-check"></i>Log Transformations: Some Final Thoughts</a><ul>
<li class="chapter" data-level="" data-path="log-transformations-some-final-thoughts.html"><a href="log-transformations-some-final-thoughts.html#power-transformations"><i class="fa fa-check"></i>Power Transformations</a><ul>
<li class="chapter" data-level="" data-path="log-transformations-some-final-thoughts.html"><a href="log-transformations-some-final-thoughts.html#ladder-of-transformations"><i class="fa fa-check"></i>Ladder of Transformations</a></li>
<li class="chapter" data-level="" data-path="log-transformations-some-final-thoughts.html"><a href="log-transformations-some-final-thoughts.html#rule-of-the-bulge"><i class="fa fa-check"></i>Rule of the Bulge</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="probability-distributions.html"><a href="probability-distributions.html"><i class="fa fa-check"></i><b>4</b> Probability Distributions</a><ul>
<li class="chapter" data-level="" data-path="probability-distributions.html"><a href="probability-distributions.html#preparation-3"><i class="fa fa-check"></i>Preparation</a></li>
<li class="chapter" data-level="4.1" data-path="probability-distributions.html"><a href="probability-distributions.html#dataset-and-research-question-2"><i class="fa fa-check"></i><b>4.1</b> Dataset and Research Question</a></li>
<li class="chapter" data-level="4.2" data-path="probability-distributions.html"><a href="probability-distributions.html#normal-distribution"><i class="fa fa-check"></i><b>4.2</b> Normal Distribution</a><ul>
<li class="chapter" data-level="4.2.1" data-path="probability-distributions.html"><a href="probability-distributions.html#other-useful-r-functions-for-working-with-probability-distributions"><i class="fa fa-check"></i><b>4.2.1</b> Other Useful R Functions for Working with Probability Distributions</a></li>
<li class="chapter" data-level="4.2.2" data-path="probability-distributions.html"><a href="probability-distributions.html#finding-cumulative-probability"><i class="fa fa-check"></i><b>4.2.2</b> Finding Cumulative Probability</a></li>
<li class="chapter" data-level="4.2.3" data-path="probability-distributions.html"><a href="probability-distributions.html#cumulative-density-and-p-value"><i class="fa fa-check"></i><b>4.2.3</b> Cumulative Density and <span class="math inline">\(p\)</span>-Value</a></li>
<li class="chapter" data-level="4.2.4" data-path="probability-distributions.html"><a href="probability-distributions.html#finding-quantiles"><i class="fa fa-check"></i><b>4.2.4</b> Finding Quantiles</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="probability-distributions.html"><a href="probability-distributions.html#students-t-distribution"><i class="fa fa-check"></i><b>4.3</b> Student’s <span class="math inline">\(t\)</span>-Distribution</a><ul>
<li class="chapter" data-level="4.3.1" data-path="probability-distributions.html"><a href="probability-distributions.html#comparing-probability-densities"><i class="fa fa-check"></i><b>4.3.1</b> Comparing Probability Densities</a></li>
<li class="chapter" data-level="4.3.2" data-path="probability-distributions.html"><a href="probability-distributions.html#comparing-cumulative-densities"><i class="fa fa-check"></i><b>4.3.2</b> Comparing Cumulative Densities</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="probability-distributions.html"><a href="probability-distributions.html#using-the-t-distribution-in-regression"><i class="fa fa-check"></i><b>4.4</b> Using the <span class="math inline">\(t\)</span>-Distribution in Regression</a></li>
<li class="chapter" data-level="4.5" data-path="probability-distributions.html"><a href="probability-distributions.html#model-level-inference-the-f-distribution"><i class="fa fa-check"></i><b>4.5</b> Model-Level Inference: The <span class="math inline">\(F\)</span>-Distribution</a><ul>
<li class="chapter" data-level="4.5.1" data-path="probability-distributions.html"><a href="probability-distributions.html#testing-the-model-level-null-hypothesis"><i class="fa fa-check"></i><b>4.5.1</b> Testing the Model-Level Null Hypothesis</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="probability-distributions.html"><a href="probability-distributions.html#mean-squares-are-variance-estimates"><i class="fa fa-check"></i><b>4.6</b> Mean Squares are Variance Estimates</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="maximum-likelihood-estimation.html"><a href="maximum-likelihood-estimation.html"><i class="fa fa-check"></i><b>5</b> Maximum Likelihood Estimation</a><ul>
<li class="chapter" data-level="" data-path="maximum-likelihood-estimation.html"><a href="maximum-likelihood-estimation.html#preparation-4"><i class="fa fa-check"></i>Preparation</a></li>
<li class="chapter" data-level="5.1" data-path="maximum-likelihood-estimation.html"><a href="maximum-likelihood-estimation.html#dataset-and-research-question-3"><i class="fa fa-check"></i><b>5.1</b> Dataset and Research Question</a></li>
<li class="chapter" data-level="5.2" data-path="maximum-likelihood-estimation.html"><a href="maximum-likelihood-estimation.html#joint-probability-density"><i class="fa fa-check"></i><b>5.2</b> Joint Probability Density</a></li>
<li class="chapter" data-level="5.3" data-path="maximum-likelihood-estimation.html"><a href="maximum-likelihood-estimation.html#likelihood"><i class="fa fa-check"></i><b>5.3</b> Likelihood</a></li>
<li class="chapter" data-level="5.4" data-path="maximum-likelihood-estimation.html"><a href="maximum-likelihood-estimation.html#maximum-likelihood"><i class="fa fa-check"></i><b>5.4</b> Maximum Likelihood</a><ul>
<li class="chapter" data-level="5.4.1" data-path="maximum-likelihood-estimation.html"><a href="maximum-likelihood-estimation.html#method-1-grid-search"><i class="fa fa-check"></i><b>5.4.1</b> Method 1: Grid Search</a></li>
<li class="chapter" data-level="5.4.2" data-path="maximum-likelihood-estimation.html"><a href="maximum-likelihood-estimation.html#log-likelihood"><i class="fa fa-check"></i><b>5.4.2</b> Log-Likelihood</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="maximum-likelihood-estimation.html"><a href="maximum-likelihood-estimation.html#maximum-likelihood-estimation-for-regression"><i class="fa fa-check"></i><b>5.5</b> Maximum Likelihood Estimation for Regression</a><ul>
<li class="chapter" data-level="5.5.1" data-path="maximum-likelihood-estimation.html"><a href="maximum-likelihood-estimation.html#large-search-spaces"><i class="fa fa-check"></i><b>5.5.1</b> Large Search Spaces</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="maximum-likelihood-estimation.html"><a href="maximum-likelihood-estimation.html#ml-estimation-in-regression-using-r"><i class="fa fa-check"></i><b>5.6</b> ML Estimation in Regression Using R</a><ul>
<li class="chapter" data-level="5.6.1" data-path="maximum-likelihood-estimation.html"><a href="maximum-likelihood-estimation.html#using-r-to-directly-compute-the-likelihood-and-log-likelihood"><i class="fa fa-check"></i><b>5.6.1</b> Using R to Directly Compute the Likelihood and Log-Likelihood</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="maximum-likelihood-estimation.html"><a href="maximum-likelihood-estimation.html#way-too-much-math"><i class="fa fa-check"></i><b>5.7</b> Way, Way, Way too Much Mathematics</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="information-criteria-for-model-selection.html"><a href="information-criteria-for-model-selection.html"><i class="fa fa-check"></i><b>6</b> Information Criteria for Model Selection</a><ul>
<li class="chapter" data-level="" data-path="information-criteria-for-model-selection.html"><a href="information-criteria-for-model-selection.html#preparation-5"><i class="fa fa-check"></i>Preparation</a></li>
<li class="chapter" data-level="6.1" data-path="information-criteria-for-model-selection.html"><a href="information-criteria-for-model-selection.html#dataset-and-research-question-4"><i class="fa fa-check"></i><b>6.1</b> Dataset and Research Question</a></li>
<li class="chapter" data-level="6.2" data-path="information-criteria-for-model-selection.html"><a href="information-criteria-for-model-selection.html#model-building"><i class="fa fa-check"></i><b>6.2</b> Model-Building</a><ul>
<li class="chapter" data-level="6.2.1" data-path="information-criteria-for-model-selection.html"><a href="information-criteria-for-model-selection.html#exploration-of-the-outcome"><i class="fa fa-check"></i><b>6.2.1</b> Exploration of the Outcome</a></li>
<li class="chapter" data-level="6.2.2" data-path="information-criteria-for-model-selection.html"><a href="information-criteria-for-model-selection.html#building-the-student-related-factors-model"><i class="fa fa-check"></i><b>6.2.2</b> Building the Student-Related Factors Model</a></li>
<li class="chapter" data-level="6.2.3" data-path="information-criteria-for-model-selection.html"><a href="information-criteria-for-model-selection.html#building-the-faculty-related-factors-model"><i class="fa fa-check"></i><b>6.2.3</b> Building the Faculty-Related Factors Model</a></li>
<li class="chapter" data-level="6.2.4" data-path="information-criteria-for-model-selection.html"><a href="information-criteria-for-model-selection.html#building-the-institution-related-factors-model"><i class="fa fa-check"></i><b>6.2.4</b> Building the Institution-Related Factors Model</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="information-criteria-for-model-selection.html"><a href="information-criteria-for-model-selection.html#candidate-statistical-models"><i class="fa fa-check"></i><b>6.3</b> Candidate Statistical Models</a></li>
<li class="chapter" data-level="6.4" data-path="information-criteria-for-model-selection.html"><a href="information-criteria-for-model-selection.html#log-likelihood-1"><i class="fa fa-check"></i><b>6.4</b> Log-Likelihood</a></li>
<li class="chapter" data-level="6.5" data-path="information-criteria-for-model-selection.html"><a href="information-criteria-for-model-selection.html#deviance-an-alternative-fit-value"><i class="fa fa-check"></i><b>6.5</b> Deviance: An Alternative Fit Value</a></li>
<li class="chapter" data-level="6.6" data-path="information-criteria-for-model-selection.html"><a href="information-criteria-for-model-selection.html#akiakes-information-criteria-aic"><i class="fa fa-check"></i><b>6.6</b> Akiake’s Information Criteria (AIC)</a></li>
<li class="chapter" data-level="6.7" data-path="information-criteria-for-model-selection.html"><a href="information-criteria-for-model-selection.html#empirical-support-for-hypotheses"><i class="fa fa-check"></i><b>6.7</b> Empirical Support for Hypotheses</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="moreinfocrit.html"><a href="moreinfocrit.html"><i class="fa fa-check"></i><b>7</b> Model Evidence</a><ul>
<li class="chapter" data-level="" data-path="moreinfocrit.html"><a href="moreinfocrit.html#preparation-6"><i class="fa fa-check"></i>Preparation</a></li>
<li class="chapter" data-level="7.1" data-path="moreinfocrit.html"><a href="moreinfocrit.html#dataset-and-research-question-5"><i class="fa fa-check"></i><b>7.1</b> Dataset and Research Question</a></li>
<li class="chapter" data-level="7.2" data-path="moreinfocrit.html"><a href="moreinfocrit.html#corrected-aic-aicc-adjusting-for-model-complexity-and-sample-size"><i class="fa fa-check"></i><b>7.2</b> Corrected AIC (AICc): Adjusting for Model Complexity and Sample Size</a></li>
<li class="chapter" data-level="7.3" data-path="moreinfocrit.html"><a href="moreinfocrit.html#model-selection-uncertainty"><i class="fa fa-check"></i><b>7.3</b> Model-Selection Uncertainty</a></li>
<li class="chapter" data-level="7.4" data-path="moreinfocrit.html"><a href="moreinfocrit.html#relative-likelihood-and-evidence-ratios"><i class="fa fa-check"></i><b>7.4</b> Relative Likelihood and Evidence Ratios</a></li>
<li class="chapter" data-level="7.5" data-path="moreinfocrit.html"><a href="moreinfocrit.html#model-probabilities"><i class="fa fa-check"></i><b>7.5</b> Model Probabilities</a></li>
<li class="chapter" data-level="7.6" data-path="moreinfocrit.html"><a href="moreinfocrit.html#tables-of-model-evidence"><i class="fa fa-check"></i><b>7.6</b> Tables of Model Evidence</a></li>
<li class="chapter" data-level="7.7" data-path="moreinfocrit.html"><a href="moreinfocrit.html#some-final-thoughts"><i class="fa fa-check"></i><b>7.7</b> Some Final Thoughts</a></li>
<li class="chapter" data-level="7.8" data-path="moreinfocrit.html"><a href="moreinfocrit.html#pretty-printing-tables-of-model-evidence"><i class="fa fa-check"></i><b>7.8</b> Pretty Printing Tables of Model Evidence</a></li>
<li class="chapter" data-level="" data-path="moreinfocrit.html"><a href="moreinfocrit.html#other-resources-2"><i class="fa fa-check"></i>Other Resources</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="intro-lmer-concepts.html"><a href="intro-lmer-concepts.html"><i class="fa fa-check"></i><b>8</b> Introduction to Mixed-Effects Models: Conceptual Ideas</a><ul>
<li class="chapter" data-level="" data-path="intro-lmer-concepts.html"><a href="intro-lmer-concepts.html#preparation-7"><i class="fa fa-check"></i>Preparation</a></li>
<li class="chapter" data-level="8.1" data-path="intro-lmer-concepts.html"><a href="intro-lmer-concepts.html#dataset-and-research-question-6"><i class="fa fa-check"></i><b>8.1</b> Dataset and Research Question</a></li>
<li class="chapter" data-level="8.2" data-path="intro-lmer-concepts.html"><a href="intro-lmer-concepts.html#join-the-student--and-classroom-level-data"><i class="fa fa-check"></i><b>8.2</b> Join the Student- and Classroom-Level Data</a></li>
<li class="chapter" data-level="8.3" data-path="intro-lmer-concepts.html"><a href="intro-lmer-concepts.html#fixed-effects-regression-model"><i class="fa fa-check"></i><b>8.3</b> Fixed-Effects Regression Model</a><ul>
<li class="chapter" data-level="8.3.1" data-path="intro-lmer-concepts.html"><a href="intro-lmer-concepts.html#residual-analysis"><i class="fa fa-check"></i><b>8.3.1</b> Residual Analysis</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="intro-lmer-concepts.html"><a href="intro-lmer-concepts.html#conceptual-idea-of-mixed-effects-models"><i class="fa fa-check"></i><b>8.4</b> Conceptual Idea of Mixed-Effects Models</a></li>
<li class="chapter" data-level="8.5" data-path="intro-lmer-concepts.html"><a href="intro-lmer-concepts.html#fitting-the-mixed-effects-regression-model-in-practice"><i class="fa fa-check"></i><b>8.5</b> Fitting the Mixed-Effects Regression Model in Practice</a></li>
<li class="chapter" data-level="8.6" data-path="intro-lmer-concepts.html"><a href="intro-lmer-concepts.html#example-2-life-satisfaction-of-nba-players"><i class="fa fa-check"></i><b>8.6</b> Example 2: Life Satisfaction of NBA Players</a><ul>
<li class="chapter" data-level="8.6.1" data-path="intro-lmer-concepts.html"><a href="intro-lmer-concepts.html#fit-the-mixed-effects-model"><i class="fa fa-check"></i><b>8.6.1</b> Fit the Mixed-Effects Model</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="intro-lmer-fitting.html"><a href="intro-lmer-fitting.html"><i class="fa fa-check"></i><b>9</b> Fitting and Interpreting Mixed-Effects Models</a><ul>
<li class="chapter" data-level="" data-path="intro-lmer-fitting.html"><a href="intro-lmer-fitting.html#preparation-8"><i class="fa fa-check"></i>Preparation</a></li>
<li class="chapter" data-level="9.1" data-path="intro-lmer-fitting.html"><a href="intro-lmer-fitting.html#dataset-and-research-question-7"><i class="fa fa-check"></i><b>9.1</b> Dataset and Research Question</a></li>
<li class="chapter" data-level="9.2" data-path="intro-lmer-fitting.html"><a href="intro-lmer-fitting.html#fitting-the-mixed-effects-regression-model-in-practice-1"><i class="fa fa-check"></i><b>9.2</b> Fitting the Mixed-Effects Regression Model in Practice</a></li>
<li class="chapter" data-level="9.3" data-path="intro-lmer-fitting.html"><a href="intro-lmer-fitting.html#example-2-life-satisfaction-of-nba-players-1"><i class="fa fa-check"></i><b>9.3</b> Example 2: Life Satisfaction of NBA Players</a><ul>
<li class="chapter" data-level="9.3.1" data-path="intro-lmer-fitting.html"><a href="intro-lmer-fitting.html#fit-the-mixed-effects-model-1"><i class="fa fa-check"></i><b>9.3.1</b> Fit the Mixed-Effects Model</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="data-codebook.html"><a href="data-codebook.html"><i class="fa fa-check"></i>Data Codebooks</a><ul>
<li class="chapter" data-level="" data-path="data-codebook.html"><a href="data-codebook.html#ed-schools-2018"><i class="fa fa-check"></i>ed-schools-2018.csv</a></li>
<li class="chapter" data-level="" data-path="data-codebook.html"><a href="data-codebook.html#evaluations"><i class="fa fa-check"></i>evaluations.csv</a></li>
<li class="chapter" data-level="" data-path="data-codebook.html"><a href="data-codebook.html#fci-2018"><i class="fa fa-check"></i>fci-2015.csv</a></li>
<li class="chapter" data-level="" data-path="data-codebook.html"><a href="data-codebook.html#mn-schools"><i class="fa fa-check"></i>mn-schools.csv</a></li>
<li class="chapter" data-level="" data-path="data-codebook.html"><a href="data-codebook.html#movies"><i class="fa fa-check"></i>movies.csv</a></li>
<li class="chapter" data-level="" data-path="data-codebook.html"><a href="data-codebook.html#nba"><i class="fa fa-check"></i>nba-player-data.csv and nba-team-data.csv</a></li>
<li class="chapter" data-level="" data-path="data-codebook.html"><a href="data-codebook.html#netherlands"><i class="fa fa-check"></i>netherlands-students.csv and netherlands-schools.csv</a></li>
<li class="chapter" data-level="" data-path="data-codebook.html"><a href="data-codebook.html#popular"><i class="fa fa-check"></i>popular-classroom.csv and popular-student.csv</a></li>
<li class="chapter" data-level="" data-path="data-codebook.html"><a href="data-codebook.html#riverview"><i class="fa fa-check"></i>riverview.csv</a></li>
<li class="chapter" data-level="" data-path="data-codebook.html"><a href="data-codebook.html#wine"><i class="fa fa-check"></i>wine.csv</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">EPsy 8252 Notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="intro-lmer-concepts" class="section level1">
<h1><span class="header-section-number">Unit 8:</span> Introduction to Mixed-Effects Models: Conceptual Ideas</h1>
<p>In this set of notes, you will learn the conceptual ideas behind linear mixed-effects models, also called multilevel models or hierarchical linear models.</p>
<hr />
<div id="preparation-7" class="section level3 unnumbered">
<h3>Preparation</h3>
<p>Before class you will need to read the <a href="https://r4ds.had.co.nz/relational-data.html">Relational data</a> chapter from following:</p>
<ul>
<li>Grolemund, G., &amp; Wickham, H. (2017). <a href="https://r4ds.had.co.nz/">R for Data Science: Visualize, model, transform, tidy, and import data</a>. **. Sebastopol, CA: O’Reilly.</li>
</ul>
<p>Focus on the information on mutating joins.</p>
<p><br /></p>
<hr />
</div>
<div id="dataset-and-research-question-6" class="section level2">
<h2><span class="header-section-number">8.1</span> Dataset and Research Question</h2>
<p>In this set of notes, we will use data from two files, the <em>netherlands-students.csv</em> file and the <em>netherlands-schools.csv</em> files (see the <a href="data-codebook.html#netherlands">data codebook</a> here). These data include student- and school-level attributes, respectively, for <span class="math inline">\(n_i=2287\)</span> 8th-grade students in the Netherlands.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Load libraries</span>
<span class="kw">library</span>(broom)
<span class="kw">library</span>(dplyr)
<span class="kw">library</span>(ggplot2)
<span class="kw">library</span>(lme4) <span class="co">#for fitting mixed-effects models</span>
<span class="kw">library</span>(readr)
<span class="kw">library</span>(sm)

<span class="co"># Read in student-level data</span>
student_data =<span class="st"> </span><span class="kw">read_csv</span>(<span class="dt">file =</span> <span class="st">&quot;~/Documents/github/epsy-8252/data/netherlands-students.csv&quot;</span>)
<span class="kw">head</span>(student_data)</code></pre>
<pre><code># A tibble: 6 x 8
  student_id school_id language_pre language_post   ses verbal_iq female
       &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;
1      17001         1           36            46    23     3.17       0
2      17002         1           36            45    10     2.67       0
3      17003         1           33            33    15    -2.33       0
4      17004         1           29            46    23    -0.834      0
5      17005         1           19            20    10    -3.83       0
6      17006         1           22            30    10    -2.33       0
# … with 1 more variable: minority &lt;dbl&gt;</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Read in school-level data</span>
school_data =<span class="st"> </span><span class="kw">read_csv</span>(<span class="dt">file =</span> <span class="st">&quot;~/Documents/github/epsy-8252/data/netherlands-schools.csv&quot;</span>)
<span class="kw">head</span>(school_data)</code></pre>
<pre><code># A tibble: 6 x 5
  school_id school_type school_ses school_verbal_iq school_minority
      &lt;dbl&gt; &lt;chr&gt;            &lt;dbl&gt;            &lt;dbl&gt;           &lt;dbl&gt;
1         1 Public              11           -1.51               60
2         2 Public              11           -2.83               10
3        10 Public              15           -1.33                4
4        12 Public              20           -2.40                5
5        15 Catholic            18           -0.334              25
6        16 Protestant          13           -0.147               0</code></pre>
<p>We will use these data to explore the question of whether verbal IQ scores predict variation in post-test language scores.</p>
</div>
<div id="join-the-student--and-classroom-level-data" class="section level2">
<h2><span class="header-section-number">8.2</span> Join the Student- and Classroom-Level Data</h2>
<p>Before analyzing the data, we need to join, or merge, the two datasets together. To do this, we will use the <code>left_join()</code> function from the <strong>dplyr</strong> package. <strong>dplyr</strong> includes six different join functions. You can read about several different join functions <a href="https://cran.r-project.org/web/packages/dplyr/vignettes/two-table.html">here</a>.</p>
<pre class="sourceCode r"><code class="sourceCode r">joined_data =<span class="st"> </span><span class="kw">left_join</span>(student_data, school_data, <span class="dt">by =</span> <span class="st">&quot;school_id&quot;</span>)
<span class="kw">head</span>(joined_data)</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["student_id"],"name":[1],"type":["dbl"],"align":["right"]},{"label":["school_id"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["language_pre"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["language_post"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["ses"],"name":[5],"type":["dbl"],"align":["right"]},{"label":["verbal_iq"],"name":[6],"type":["dbl"],"align":["right"]},{"label":["female"],"name":[7],"type":["dbl"],"align":["right"]},{"label":["minority"],"name":[8],"type":["dbl"],"align":["right"]},{"label":["school_type"],"name":[9],"type":["chr"],"align":["left"]},{"label":["school_ses"],"name":[10],"type":["dbl"],"align":["right"]},{"label":["school_verbal_iq"],"name":[11],"type":["dbl"],"align":["right"]},{"label":["school_minority"],"name":[12],"type":["dbl"],"align":["right"]}],"data":[{"1":"17001","2":"1","3":"36","4":"46","5":"23","6":"3.1659379","7":"0","8":"0","9":"Public","10":"11","11":"-1.514062","12":"60"},{"1":"17002","2":"1","3":"36","4":"45","5":"10","6":"2.6659379","7":"0","8":"1","9":"Public","10":"11","11":"-1.514062","12":"60"},{"1":"17003","2":"1","3":"33","4":"33","5":"15","6":"-2.3340621","7":"0","8":"0","9":"Public","10":"11","11":"-1.514062","12":"60"},{"1":"17004","2":"1","3":"29","4":"46","5":"23","6":"-0.8340621","7":"0","8":"0","9":"Public","10":"11","11":"-1.514062","12":"60"},{"1":"17005","2":"1","3":"19","4":"20","5":"10","6":"-3.8340621","7":"0","8":"0","9":"Public","10":"11","11":"-1.514062","12":"60"},{"1":"17006","2":"1","3":"22","4":"30","5":"10","6":"-2.3340621","7":"0","8":"1","9":"Public","10":"11","11":"-1.514062","12":"60"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
</div>
<div id="fixed-effects-regression-model" class="section level2">
<h2><span class="header-section-number">8.3</span> Fixed-Effects Regression Model</h2>
<p>To examine the research question of whether verbal IQ scores predict variation in post-test language scores, we might regress language scores on the verbal IQ scores using the <code>lm()</code> function. The <code>lm()</code> function fits a <em>fixed-effects regression model</em>.</p>
<pre class="sourceCode r"><code class="sourceCode r">lm<span class="fl">.1</span> =<span class="st"> </span><span class="kw">lm</span>(language_post <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>verbal_iq, <span class="dt">data =</span> joined_data)

<span class="co"># Model-level output</span>
<span class="kw">glance</span>(lm<span class="fl">.1</span>)</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["r.squared"],"name":[1],"type":["dbl"],"align":["right"]},{"label":["adj.r.squared"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["sigma"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["statistic"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["p.value"],"name":[5],"type":["dbl"],"align":["right"]},{"label":["df"],"name":[6],"type":["int"],"align":["right"]},{"label":["logLik"],"name":[7],"type":["dbl"],"align":["right"]},{"label":["AIC"],"name":[8],"type":["dbl"],"align":["right"]},{"label":["BIC"],"name":[9],"type":["dbl"],"align":["right"]},{"label":["deviance"],"name":[10],"type":["dbl"],"align":["right"]},{"label":["df.residual"],"name":[11],"type":["int"],"align":["right"]}],"data":[{"1":"0.3718798","2":"0.3716049","3":"7.137338","4":"1352.839","5":"5.020594e-233","6":"2","7":"-7738.844","8":"15483.69","9":"15500.89","10":"116401.5","11":"2285"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Coefficient-level output</span>
<span class="kw">tidy</span>(lm<span class="fl">.1</span>)</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["term"],"name":[1],"type":["chr"],"align":["left"]},{"label":["estimate"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["std.error"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["statistic"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["p.value"],"name":[5],"type":["dbl"],"align":["right"]}],"data":[{"1":"(Intercept)","2":"40.934849","3":"0.14924616","4":"274.27741","5":"0.000000e+00"},{"1":"verbal_iq","2":"2.653896","3":"0.07215406","4":"36.78096","5":"5.020594e-233"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>The model-level summary information suggests that differences in verbal IQ scores explains 37.2% of the variation in post-test language scores, <span class="math inline">\(F(1,2285)=1352.84\)</span>, <span class="math inline">\(p&lt;0.001\)</span>. The estimated intercept suggests that the average predicted post-test language scores for students with a mean verbal IQ score (= 0) is 40.93 (<span class="math inline">\(p&lt;.001\)</span>). The estimated slope indicates that each one-point difference in verbal IQ score is associated with a difference in post-test language scores of <span class="math inline">\(2.65\)</span>, on average (<span class="math inline">\(p&lt;.001\)</span>). To have faith in the analytic results from this model, we need to evaluate whether the assumptions are satisfied.</p>
<div id="residual-analysis" class="section level3">
<h3><span class="header-section-number">8.3.1</span> Residual Analysis</h3>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Obtain the fortified data frame</span>
out =<span class="st"> </span><span class="kw">augment</span>(lm<span class="fl">.1</span>)
<span class="kw">head</span>(out)</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["language_post"],"name":[1],"type":["dbl"],"align":["right"]},{"label":["verbal_iq"],"name":[2],"type":["dbl"],"align":["right"]},{"label":[".fitted"],"name":[3],"type":["dbl"],"align":["right"]},{"label":[".se.fit"],"name":[4],"type":["dbl"],"align":["right"]},{"label":[".resid"],"name":[5],"type":["dbl"],"align":["right"]},{"label":[".hat"],"name":[6],"type":["dbl"],"align":["right"]},{"label":[".sigma"],"name":[7],"type":["dbl"],"align":["right"]},{"label":[".cooksd"],"name":[8],"type":["dbl"],"align":["right"]},{"label":[".std.resid"],"name":[9],"type":["dbl"],"align":["right"]}],"data":[{"1":"46","2":"3.1659379","3":"49.33692","4":"0.2728683","5":"-3.336918","6":"0.0014616170","7":"7.138558","8":"1.602111e-04","9":"-0.4678718"},{"1":"45","2":"2.6659379","3":"48.00997","4":"0.2434669","5":"-3.009970","6":"0.0011636094","7":"7.138622","8":"1.037147e-04","9":"-0.4219673"},{"1":"33","2":"-2.3340621","3":"34.74049","4":"0.2250267","5":"-1.740492","6":"0.0009940216","7":"7.138807","8":"2.961429e-05","9":"-0.2439786"},{"1":"46","2":"-0.8340621","3":"38.72134","4":"0.1609229","5":"7.278665","6":"0.0005083502","7":"7.137274","8":"2.646096e-04","9":"1.0200604"},{"1":"20","2":"-3.8340621","3":"30.75965","4":"0.3143340","5":"-10.759649","6":"0.0019395911","7":"7.135342","8":"2.212535e-03","9":"-1.5089798"},{"1":"30","2":"-2.3340621","3":"34.74049","4":"0.2250267","5":"-4.740492","6":"0.0009940216","7":"7.138210","8":"2.196868e-04","9":"-0.6645125"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Normality</span>
<span class="kw">sm.density</span>(out<span class="op">$</span>.std.resid, <span class="dt">model =</span> <span class="st">&quot;normal&quot;</span>, <span class="dt">xlab =</span> <span class="st">&quot;Standardized residuals&quot;</span>)

<span class="co"># All other assumptions</span>
<span class="kw">ggplot</span>(<span class="dt">data =</span> out, <span class="kw">aes</span>(<span class="dt">x =</span> .fitted, <span class="dt">y =</span> .std.resid)) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_point</span>() <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_hline</span>(<span class="dt">yintercept =</span> <span class="dv">0</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">theme_bw</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Fitted values&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Standardized residuals&quot;</span>)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-6"></span>
<img src="epsy-8252-notes_files/figure-html/unnamed-chunk-6-1.png" alt="Density plot of the standardized residuals and scatterplot of the standardized residuals versus the fitted values from the fixed-effects regression model." width="50%" /><img src="epsy-8252-notes_files/figure-html/unnamed-chunk-6-2.png" alt="Density plot of the standardized residuals and scatterplot of the standardized residuals versus the fitted values from the fixed-effects regression model." width="50%" />
<p class="caption">
Figure 8.1: Density plot of the standardized residuals and scatterplot of the standardized residuals versus the fitted values from the fixed-effects regression model.
</p>
</div>
<p>The assumption that the mean residual is 0 seems reasonably satisfied, however those of normality and homoscedasticity seem less feasible, especially given the large sample size. More importantly, the assumption of independence (which we don’t evaluate from the common residual plots) is probably not tenable. Students’ post-test language scores (and thus the residuals) are probably correlated within schools—this is a violation of independence which assumes that the correlation between student’s residuals is 0. If we have a variable that identifies classroom, we can actually examine this by plotting the residuals separately for each classroom.</p>
<p>In our case, we do have a variable that identifies classroom (<code>school_id</code>). We need to mutate this variable into the augmented dataset. This variable has 131 different levels, which means that we would be looking at 131 different residual plots. When we use <code>facet_wrap()</code> with that many levels each plot will be too small to see, so we will instead select a random sample of, say, 25 of the classrooms to evaluate.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Make random sample reproducible</span>
<span class="kw">set.seed</span>(<span class="dv">100</span>)

<span class="co"># Draw random sample of 25 schools without replacement</span>
my_sample =<span class="st"> </span><span class="kw">sample</span>(school_data<span class="op">$</span>school_id, <span class="dt">size =</span> <span class="dv">25</span>, <span class="dt">replace =</span> <span class="ot">FALSE</span>)

<span class="co"># Mutate on school ID and draw random sample</span>
out =<span class="st"> </span>out <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">school_id =</span> joined_data<span class="op">$</span>school_id) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(school_id <span class="op">%in%</span><span class="st"> </span>my_sample)

<span class="co">### Show residuals by school</span>
<span class="kw">ggplot</span>(<span class="dt">data =</span> out, <span class="kw">aes</span>(<span class="dt">x =</span> .fitted, <span class="dt">y =</span> .std.resid)) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_point</span>() <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_hline</span>(<span class="dt">yintercept =</span> <span class="dv">0</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">theme_bw</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Fitted values&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Studentized residuals&quot;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">facet_wrap</span>(<span class="op">~</span>school_id, <span class="dt">nrow =</span> <span class="dv">5</span>)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-7"></span>
<img src="epsy-8252-notes_files/figure-html/unnamed-chunk-7-1.png" alt="Scatterplots of the standardized residuals versus the fitted values from the fixed-effects regression model stratified by team." width="90%" />
<p class="caption">
Figure 8.2: Scatterplots of the standardized residuals versus the fitted values from the fixed-effects regression model stratified by team.
</p>
</div>
<p>The residuals for several of the schools show a systematic trends of being primarily positive or negative within schools. For example, the residuals for several schools (e.g., 47, 256 258) are primarily negative. This is a sign of non-independence of the residuals. If we hadn’t had the school ID variable we could have still made a logical argument about this non-independence via substantive knowledge. For example, students who attend a “high performing” will likely tend to have positive residuals (scores above average relative to the population), even after accounting for their verbal IQ scores.</p>
<p>To account for this within-school correlation we need to use a statistical model that accounts for the correlation among the residuals within schools. This is what <em>mixed-effects models</em> bring to the table. By correctly modeling the non-independence, we get more accurate standard errors and <em>p</em>-values.</p>
<p>Another benefit of using mixed-effects models is that we also get estimates of the variation accounted for at both the school- and student-levels. This disaggregating of the variation allows us to see which level is explaining more variation and to study predictors appropriate to explaining that variation. For example, suppose that you disaggregated the variation in language scores and found that:</p>
<ul>
<li>96% of the variation in these scores was at the student-level, and</li>
<li>3% of the variation in these scores was at the classroom-level, and</li>
<li>1% of the variation in these scores was at the school-level.</li>
</ul>
<p>By including school-level or classroom-level predictors in the model, you would only be “chipping away” at that 1% or 3%, respectively. You should focus your attention and resources on student-level predictors!</p>
</div>
</div>
<div id="conceptual-idea-of-mixed-effects-models" class="section level2">
<h2><span class="header-section-number">8.4</span> Conceptual Idea of Mixed-Effects Models</h2>
<p>In this section we will outline the conceptual ideas behind mixed-effects models by linking the ideas behind these models to the conventional, fixed-effects regression model. <em>It is important to realize that this is just conceptual in nature. Its purpose is only to help you understand the output you get from a mixed-effects model analysis.</em></p>
<p>To begin, we remind you of the fitted equation we obtained earlier from the fixed-effects regression:</p>
<p><span class="math display">\[
\hat{\mathrm{Language~Score}_i} = 34.19 + 2.04(\mathrm{Verbal~IQ}_i)
\]</span></p>
<p>Mixed-effects regression actually fits a global model (like the one above) AND a school-specific model for each school. Conceptually, this is like fitting a regression model for each school separately. Below I show the results (for 5 of the schools) of fitting a different regression model to each school, but keep in mind that this is only to help you understand.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Fit school models</span>
school_models =<span class="st"> </span>joined_data <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(school_id) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">do</span>(<span class="dt">mod =</span> <span class="kw">lm</span>(language_post  <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>verbal_iq, <span class="dt">data =</span> .)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">tidy</span>(mod) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">head</span>(., <span class="dv">10</span>)

<span class="co"># View coefficients from fitted models</span>
school_models</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["school_id"],"name":[1],"type":["dbl"],"align":["right"]},{"label":["term"],"name":[2],"type":["chr"],"align":["left"]},{"label":["estimate"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["std.error"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["statistic"],"name":[5],"type":["dbl"],"align":["right"]},{"label":["p.value"],"name":[6],"type":["dbl"],"align":["right"]}],"data":[{"1":"1","2":"(Intercept)","3":"39.789130","4":"1.5831305","5":"25.133196","6":"3.155347e-18"},{"1":"1","2":"verbal_iq","3":"2.238435","4":"0.5407876","5":"4.139213","6":"3.979394e-04"},{"1":"2","2":"(Intercept)","3":"27.350441","4":"4.1789775","5":"6.544769","6":"1.247111e-03"},{"1":"2","2":"verbal_iq","3":"1.283019","4":"1.2156400","5":"1.055427","6":"3.395357e-01"},{"1":"10","2":"(Intercept)","3":"38.086739","4":"2.8208323","5":"13.501951","6":"8.785589e-04"},{"1":"10","2":"verbal_iq","3":"5.761905","4":"1.4321120","5":"4.023362","6":"2.758449e-02"},{"1":"12","2":"(Intercept)","3":"36.105947","4":"3.8181470","5":"9.456406","6":"3.427722e-07"},{"1":"12","2":"verbal_iq","3":"2.182371","4":"1.4204046","5":"1.536443","6":"1.484049e-01"},{"1":"15","2":"(Intercept)","3":"32.113990","4":"3.8493701","5":"8.342661","6":"1.611045e-04"},{"1":"15","2":"verbal_iq","3":"3.708861","4":"1.7131003","5":"2.164999","6":"7.356769e-02"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>As an example, let’s focus on the fitted model for School 1.</p>
<p><span class="math display">\[
\hat{\mathrm{Language~Score}_i} = 39.79 + 2.24(\mathrm{Verbal~IQ}_i)
\]</span></p>
<p>Comparing this school-specific model to the global model, we find that School 1’s intercept is higher than the intercept from the global model (by 5.65) and it’s slope is also higher than the slope from the global model (by 0.20). We can actually re-write the school-specific model using these ideas:</p>
<p><span class="math display">\[
\hat{\mathrm{Language~Score}_i} = \bigg[34.19 + 5.65\bigg] + \bigg[2.04 + 0.20\bigg](\mathrm{Verbal~IQ}_i)
\]</span></p>
<p>In the language of mixed-effects modeling:</p>
<ul>
<li>The global intercept and slope are referred to as <em>fixed-effects</em>. (These are also sometimes referred to as <em>between-groups</em> effects.)
<ul>
<li>The fixed-effect of intercept is <span class="math inline">\(34.19\)</span>; and</li>
<li>The fixed effect of the slope is <span class="math inline">\(2.04\)</span>.</li>
</ul></li>
<li>The school-specific deviations from the fixed-effect values are referred to as <em>random-effects</em>. (These are also sometimes referred to as <em>within-groups</em> effects.)
<ul>
<li>The random-effect of the intercept for School 1 is <span class="math inline">\(+5.65\)</span>; and</li>
<li>The random-effect of the slope for School 1 is <span class="math inline">\(+0.20\)</span>.</li>
</ul></li>
</ul>
<p>Note, each school could potentially have a different random-effect for intercept and slope. For example, writing the team-specific fitted equation for School 2 in this manner,</p>
<p><span class="math display">\[
\begin{split}
\hat{\mathrm{Language~Score}_i} &amp;= 27.35 + 1.28(\mathrm{Verbal~IQ}_i)\\
 &amp;= \bigg[34.19 - 6.84\bigg] + \bigg[2.04 - 0.76\bigg](\mathrm{Verbal~IQ}_i).\\
\end{split}
\]</span></p>
<p>In this model:</p>
<ul>
<li>The fixed-effects (global effects) are the same as they were for School 1.
<ul>
<li>The fixed-effect of intercept is <span class="math inline">\(34.19\)</span>; and</li>
<li>The fixed effect of the slope is <span class="math inline">\(2.04\)</span>.</li>
</ul></li>
<li>The random-effect of intercept for School 2 is <span class="math inline">\(-6.84\)</span>.</li>
<li>The random-effect of slope for School 2 is <span class="math inline">\(-0.76\)</span>.</li>
</ul>
</div>
<div id="fitting-the-mixed-effects-regression-model-in-practice" class="section level2">
<h2><span class="header-section-number">8.5</span> Fitting the Mixed-Effects Regression Model in Practice</h2>
<p>In practice, we use the <code>lmer()</code> function from the <strong>lme4</strong> library to fit mixed-effect regression models. This function will essentially do what we did in the previous section, but rather than independently fitting the team-specific models, it will fit all these models simultaneously and make use of the information in all the clusters (schools) to do this. This will result in better estimates for both the fixed- and random-effects.</p>
<p>The syntax looks similar to the syntax we use in <code>lm()</code> except now we split it into two parts. The first part of the syntax gives a model formula to specify the outcome and fixed-effects included in the model. This is identical to the syntax we used in the <code>lm()</code> function. In our example: <code>language_post ~ 1 + verbal_iq</code> indicating that we want to fit a model that includes fixed-effects for both the intercept and the effect of verbal IQ score.</p>
<p>We also have to declare that we want to fit a model for each school. To do this, we will include a random-effect for intercept. (We could also include a random-effect of verbal IQ, but to keep it simpler right now, we only include the RE of intercept.) The second part of the syntax declares this: <code>(1 | school_id)</code>. This says fit school-specific models that vary in their intercepts. This is literally added to the fixed-effects formula using <code>+</code>. The complete syntax is:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Fit mixed-effects regression model</span>
lmer<span class="fl">.1</span> =<span class="st"> </span><span class="kw">lmer</span>(language_post <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>verbal_iq <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>school_id), <span class="dt">data =</span> joined_data)</code></pre>
<p>To view the fixed-effects, we use the <code>fixef()</code> function.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">fixef</span>(lmer<span class="fl">.1</span>)</code></pre>
<pre><code>(Intercept)   verbal_iq 
  40.608232    2.487591 </code></pre>
<p>This gives the coefficients for the fixed-effects part of the model (i.e., the global model),</p>
<p><span class="math display">\[
\hat{\mathrm{Language~Score}_{ij}} = 40.61 + 2.49(\mathrm{Verbal~IQ}_{ij})
\]</span></p>
<p>Note that the notation now includes two subscripts. The <em>i</em> subscript still indicates the <em>i</em>th student, and the new <em>j</em> subscript indicates that the student was from the <em>j</em>th school. Since we accounted for school in the model (schools are allowed to have different intercepts) we need to now identify that in the equation. We interpret these coefficients from the fixed-effects equation exactly like <code>lm()</code> coefficients. Here,</p>
<ul>
<li>The predicted average post-test language score for students with a mean verbal IQ score (=0) is 40.61.</li>
<li>Each one-point difference in verbal IQ score is associated with a 2.49-point difference in language scores, on average.</li>
</ul>
<p>To view the school-specific random-effects, we use the <code>ranef()</code> function (only the first 5 rows are shown).</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ranef</span>(lmer<span class="fl">.1</span>)</code></pre>
<pre><code>$school_id
    (Intercept)
1   -0.37573940
2   -6.04469893
10  -3.66481710
12  -2.91463441
15  -5.74351132</code></pre>
<p>The random-effects indicate how the school-specific intercept differs from the overall average intercept. For example, the intercept for School 1 is approximately 0.38-points lower than the average intercept of 40.61 (the fixed-effect). This implies that, on average, students from School 1 with a mean verbal IQ score (=0) have an average post-test language score that is 0.38-points lower than their peers who also have a mean verbal IQ score.</p>
<p>From the estimated fixed- and random-effects, we can re-construct each school-specific fitted equation if we are so inclined. For example, to construct the school-specific fitted equation for School 1, we combine the estimated coefficients for the fixed-effects and the estimated random-effect for School 1:</p>
<p><span class="math display">\[
\begin{split}
\hat{\mathrm{Language~Score}_{i}} &amp;= \bigg[ 40.61 -0.376 \bigg]+ 2.49(\mathrm{Verbal~IQ}_{i}) \\[1ex]
&amp;= 40.2 + 2.49(\mathrm{Verbal~IQ}_{i}) 
\end{split}
\]</span></p>
<p>In this notation, the <em>j</em> part of the subscript is dropped since <em>j</em> is now fixed to a specific school; <span class="math inline">\(j=1\)</span>.</p>
</div>
<div id="example-2-life-satisfaction-of-nba-players" class="section level2">
<h2><span class="header-section-number">8.6</span> Example 2: Life Satisfaction of NBA Players</h2>
<p>As a second example, we will explore the question of whether NBA players’ success is related to life satisfaction. To do this, we will use two datasets, the <em>nba-player-data.csv</em> and <em>nba-team-data.csv</em> file (see the <a href="data-codebook.html#nba">data codebook</a> here). These data include player- and team-level attributes for <span class="math inline">\(n=300\)</span> players and <span class="math inline">\(n=30\)</span> teams, respectively. To begin, we will import both the player-level and team-level datasets and then join them together.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Read in player-level data</span>
nba_players =<span class="st"> </span><span class="kw">read_csv</span>(<span class="dt">file =</span> <span class="st">&quot;~/Documents/github/epsy-8252/data/nba-player-data.csv&quot;</span>)

<span class="co"># Read in team-level data</span>
nba_teams =<span class="st"> </span><span class="kw">read_csv</span>(<span class="dt">file =</span> <span class="st">&quot;~/Documents/github/epsy-8252/data/nba-team-data.csv&quot;</span>)

<span class="co"># Join the datasets together</span>
nba =<span class="st"> </span>nba_players <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">left_join</span>(nba_teams, <span class="dt">by =</span> <span class="st">&quot;team&quot;</span>)

<span class="kw">head</span>(nba)</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["player"],"name":[1],"type":["chr"],"align":["left"]},{"label":["team"],"name":[2],"type":["chr"],"align":["left"]},{"label":["success"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["life_satisfaction"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["coach"],"name":[5],"type":["chr"],"align":["left"]},{"label":["coach_experience"],"name":[6],"type":["dbl"],"align":["right"]}],"data":[{"1":"Daniel Hamilton","2":"Atlanta Hawks","3":"0","4":"12.100","5":"Lloyd Pierce","6":"0"},{"1":"Alex Poythress","2":"Atlanta Hawks","3":"0","4":"13.490","5":"Lloyd Pierce","6":"0"},{"1":"Jaylen Adams","2":"Atlanta Hawks","3":"0","4":"18.804","5":"Lloyd Pierce","6":"0"},{"1":"Miles Plumlee","2":"Atlanta Hawks","3":"0","4":"18.000","5":"Lloyd Pierce","6":"0"},{"1":"PJ Dozier","2":"Boston Celtics","3":"0","4":"12.220","5":"Brad Stevens","6":"2"},{"1":"Ed Davis","2":"Brooklyn Nets","3":"0","4":"16.000","5":"Kenny Atkinson","6":"1"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>We want to fit a model that regresses the <code>life_satisfaction</code> scores on the <code>success</code> values. In these data, however, we might expect that the life satisfaction of players is correlated within team. To account for that fact, we can include a random-effect of intercept in our regression model.</p>
<div id="fit-the-mixed-effects-model" class="section level3">
<h3><span class="header-section-number">8.6.1</span> Fit the Mixed-Effects Model</h3>
<p>Below we fit a mixed-effects regression model to predict variation in life satisfaction scores that includes success as a predictor. We also include a random-effect of intercept to account for the within-team correlation of life satisfaction scores. The statistical model is:</p>
<p><span class="math display">\[
\mathrm{Life~Satisfaction}_{ij} = \bigg[\beta_0 + b_{0j} \bigg] + \beta_1(\mathrm{Success}_{ij}) + \epsilon_{ij}
\]</span></p>
<p>We fit the model using <code>lmer()</code> as:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Fit model</span>
lmer<span class="fl">.1</span> =<span class="st"> </span><span class="kw">lmer</span>(life_satisfaction <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>success <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>team), <span class="dt">data =</span> nba)</code></pre>
<p>We can then extract the fixed-effects estimates using the <code>fixef()</code> function.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Get fixed-effects</span>
<span class="kw">fixef</span>(lmer<span class="fl">.1</span>)</code></pre>
<pre><code>(Intercept)     success 
  11.574601    1.666015 </code></pre>
<p>We write the fitted fixed-effects model as:</p>
<p><span class="math display">\[
\hat{\mathrm{Life~Satisfaction}}_{ij} = 11.57 + 1.67(\mathrm{Success}_{ij})
\]</span></p>
<p>Again, we can interpret these fixed-effects estimates the same way we do any other regression coefficient.</p>
<ul>
<li>The predicted average life satisfaction for NBA players with a success score of 0 (free-throw percentage in the lowest 20%) is 11.57.</li>
<li>Each one-unit difference in success (one-quantile difference) is associated with a 1.67-point difference in life satisfaction score, on average.</li>
</ul>
<p>If we are interested in the fitted model for a SPECIFIC team, we can extract the random-effect of intercept for that team and add it to the fixed-effect intercept estimate. For example, the equation for the Minnesota Timberwolves is:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Obtain random-effects</span>
<span class="kw">ranef</span>(lmer<span class="fl">.1</span>)</code></pre>
<pre><code>$team
                       (Intercept)
Atlanta Hawks            2.7473728
Boston Celtics           5.3593594
Brooklyn Nets            4.1005305
Charlotte Hornets        1.1514595
Chicago Bulls           -3.4810574
Cleveland Cavaliers      0.9738921
Dallas Mavericks        -6.1708318
Denver Nuggets           4.0877313
Detroit Pistons         -2.3659077
Golden State Warriors   -1.8955266
Houston Rockets         -2.3037737
Indiana Pacers          -1.4243752
Los Angeles Clippers     5.5527559
Los Angeles Lakers      -5.0070905
Memphis Grizzlies        0.6390959
Miami Heat               0.6748741
Milwaukee Bucks         -5.8198313
Minnesota Timberwolves   3.6615923
New Orleans Pelicans    -1.3425660
New York Knicks         -1.9478744
Oklahoma City Thunder   -1.5290765
Orlando Magic           -3.4961290
Philadelphia 76ers       4.6166814
Phoenix Suns            -6.1341120
Portland Trail Blazers   0.3600073
Sacramento Kings        -3.4140175
San Antonio Spurs        0.1794157
Toronto Raptors          3.8491342
Utah Jazz                6.2954339
Washington Wizards       2.0828334</code></pre>
<p><span class="math display">\[
\begin{split}
\hat{\mathrm{Life~Satisfaction}}_{i} &amp;= \bigg[11.57 + 3.66 \bigg] + 1.67(\mathrm{Success}_{i}) \\[1ex]
&amp;= 15.23 + 1.67(\mathrm{Success}_{i})
\end{split}
\]</span></p>
<p>For Timberwolves players,</p>
<ul>
<li>The predicted average life satisfaction for Timberwolves players with a success score of 0 (free-throw percentage in the lowest 20%) is 15.23. This is a score that is 3.66 points above average for all NBA players with a success score of 0.</li>
<li>Each one-unit difference in success is associated with a 1.67-point difference in life satisfaction score for Timberwolves players, on average. This is the same rate-of-change as for NBA players in general.</li>
</ul>
<p>As a comparison, we can also consider the equation for the Phoenix Suns:</p>
<p><span class="math display">\[
\begin{split}
\hat{\mathrm{Life~Satisfaction}}_{i} &amp;= \bigg[11.57 - 6.13 \bigg] + 1.67(\mathrm{Success}_{i}) \\[1ex]
&amp;= 5.44 + 1.67(\mathrm{Success}_{i})
\end{split}
\]</span></p>
<ul>
<li>The predicted average life satisfaction for Suns players with a success score of 0 (free-throw percentage in the lowest 20%) is 5.44. This is a score that is 6.13 points below average for all NBA players with a success score of 0.</li>
<li>Each one-unit difference in success is associated with a 1.67-point difference in life satisfaction score for Suns players, on average. This is the same rate-of-change as for NBA players in general.</li>
</ul>
<p>Comparing these two team’s equations gives us some insight into why the effects are referred to as <em>fixed-effects</em> or <em>random-effects</em>.</p>
<p><span class="math display">\[
\begin{split}
\mathbf{Timberwolves:~}\hat{\mathrm{Life~Satisfaction}}_{i} &amp;= \bigg[11.57 + 3.66 \bigg] + 1.67(\mathrm{Success}_{i}) \\[1ex]
\mathbf{Suns:~}\hat{\mathrm{Life~Satisfaction}}_{i} &amp;= \bigg[11.57 - 6.13 \bigg] + 1.67(\mathrm{Success}_{i}) \\[1ex]
\end{split}
\]</span></p>
<p>In the two equations, the fixed-effects of intercept (11.57) and success (1.67) are represented in both equations; they are fixed. On the other hand, the random-effect is different for each team. Since we included a random-effect of intercept in out model, this means that the intercept value for each team equation will be different.</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="moreinfocrit.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="intro-lmer-fitting.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": {},
"instapper": false
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
},
"collapse": "section",
"toolbar": null,
"position": "fixed",
"search": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
