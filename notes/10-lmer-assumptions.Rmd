---
title: "Linear Mixed-Effects Models: Alternative Representations and Assumptions"
date: "`r Sys.Date()`"
header-includes:
   - \usepackage{xcolor}
   - \usepackage[framemethod=tikz]{mdframed}
   - \usepackage{graphicx}
   - \usepackage{rotating}
   - \usepackage{booktabs}
   - \usepackage{float}
   - \usepackage{array}
   - \definecolor{umn}{RGB}{153, 0, 85}
   - \definecolor{umn2}{rgb}{0.1843137, 0.4509804, 0.5372549}
   - \definecolor{myorange}{HTML}{EA6153}
output: 
  pdf_document:
    latex_engine: xelatex
    highlight: zenburn
    fig_width: 6
    fig_height: 6
mainfont: "Sabon"
sansfont: "Futura"
monofont: Inconsolata
urlcolor: "umn2"
bibliography: epsy8252.bib
csl: apa-single-spaced.csl
always_allow_html: yes
---


```{r setup, include=FALSE}
options(digits = 3, scipen = 99)

library(knitr)
knitr::opts_chunk$set(
  prompt = FALSE,
  comment = NA,
  message = FALSE,
  warning = FALSE,
  tidy = FALSE,
  fig.align = 'center',
  out.width = '3in',
  echo = TRUE
  )

#library(printr)

options(kableExtra.latex.load_packages = FALSE)
library(kableExtra)
```

\frenchspacing


In this set of notes, you will learn alternative ways of representing the linear mixed-effects model. You will also learn about the underlying assumptions for the linear mixed-effects model, as well as how to evaluate them empirically.


# Dataset and Research Question

In this set of notes, we will use data from two files, the *netherlands-students.csv* file and the *netherlands-schools.csv* file (see the [data codebook](https://zief0002.github.io/book-8252/data-codebook.html#netherlands) here). These data include student- and school-level attributes, respectively, for $n_i=2287$ 8th-grade students in the Netherlands.

```{r message=FALSE, paged.print=FALSE}
# Load libraries
library(AICcmodavg)
library(broom)
library(dplyr)
library(ggplot2)
library(lme4) #for fitting mixed-effects models
library(readr)
library(sm)
library(tidyr)

# Read in student-level data
student_data = read_csv(file = "~/Documents/github/epsy-8252/data/netherlands-students.csv")

# Read in school-level data
school_data = read_csv(file = "~/Documents/github/epsy-8252/data/netherlands-schools.csv")

# Join the two datasets together
joined_data = left_join(student_data, school_data, by = "school_id")
head(joined_data)
```

We will use these data to explore the question of whether verbal IQ scores predict variation in post-test language scores.

\newpage

# Statistical Model: Expressed as a Mixed-Effects Model

In the last unit we fitted several linear mixed-effects models to predict variation in students' post-test language scores. The statistical models for these are presented below.

$$
\begin{split}
\mathbf{Model~1:~}\mathrm{Language~Score}_{ij} &= \big[\beta_0 + b_{0j}\big] + \epsilon_{ij} \\[1em]
\mathbf{Model~2:~}\mathrm{Language~Score}_{ij} &= \big[\beta_0 + b_{0j}\big] + \beta_1(\mathrm{Verbal~IQ}_{ij}) + \epsilon_{ij} \\[1em]
\mathbf{Model~3:~}\mathrm{Language~Score}_{ij} &= \big[\beta_0 + b_{0j}\big] + \beta_1(\mathrm{Verbal~IQ}_{ij}) + \beta_2(\mathrm{SES}_{ij}) + \beta_3(\mathrm{Public}_{\bullet j}) + \epsilon_{ij}
\end{split}
$$

This representation of the models is referred to as the **composite model** or the **mixed-effects model** since they include both the fixed- and random-effects in the same equation.


# Writing the Statistical Model as a Set of Multilevel Equations

Another way we can express the model is by seperating the mixed-effects model equation into multiple equations; one for each level of variation. For example, each of the mixed-effects models listed above could be separated into two equations: a student-level equation (Level-1) and a set of school-level equations (Level-2). As an example, take the equation for Model 2:

$$
\mathrm{Language~Score}_{ij} = \big[\beta_0 + b_{0j}\big] + \beta_1(\mathrm{Verbal~IQ}_{ij}) + \epsilon_{ij}
$$

We initially write the student-level, or Level-1 equation. The level-1 equation includes all the fixed-effects and the random error term from the mixed-effects model. When writing the Level-1 model, we add a *j* subscript to each of the fixed-effects to indicate that the particular effect may be unique to a particular school. The Level-1 equation for Model 2 is:

$$
\mathrm{Language~Score}_{ij} = \beta_{0j} + \beta_{1j}(\mathrm{Verbal~IQ}_{ij}) + \epsilon_{ij}
$$

The Level-1 equation describes the variation in students' post-test language scores. It says that this variation is decomposed into that which is explained by differences in students' verbal IQ scores and unexplained random error. The *j* subscipt on the fixed-effects terms indicates that the intercept and effect of verbal IQ scores is the same for all students within a particular school.

After writing the Level-1 equation, we can write out the Level-2, or school-level equation(s). There will be a Level-2 equation for each of the fixed-effects in the Level-1 model. In our example, since we have two fixed-effects in the Level-1 model ($\beta_0$ and $\beta_1$), there will be two Level-2 equations. In each Level-2 equations, the outcome is one of the fixed-effects from the Level-1 equation. These equations describe how the school-specific intercept and slopes differ across schools. As such, they may include the random-effects and any school-level effects. For example, we can write the Level-2 equations for Model 2 as:

$$
\begin{split}
\beta_{0j} &= \beta_0 + b_{0j}\\
\beta_{1j} &= \beta_1\\
\end{split}
$$

These equations indicate that the school-specific intercepts are a function of some part common to all schools ($\beta_0$; a fixed-effect) and some deviation from that ($b_{0j}$; a random-effect of intercept). The random-effect is the reason that schools can have different intercepts. The school-specific slope, on the other hand, dos not vary by school; it is the same for each school.

Together these equations are referred to as the set of multilevel equations:

$$
\begin{split}
\mathbf{Level\mbox{-}1:}\\
&~ \mathrm{Language~Score}_{ij} = \beta_{0j} + \beta_{1j}(\mathrm{Verbal~IQ}_{ij}) + \epsilon_{ij}\\
\mathbf{Level\mbox{-}2:}\\
&~ \beta_{0j} = \beta_0 + b_{0j}\\
&~ \beta_{1j} = \beta_1\\
\end{split}
$$

## Multilevel Equation for Model 3

As a second example, consider Model 3:

$$
\begin{split}
\mathrm{Language~Score}_{ij} &= \big[\beta_0 + b_{0j}\big] + \beta_1(\mathrm{Verbal~IQ}_{ij}) + \beta_2(\mathrm{SES}_{ij}) + \beta_3(\mathrm{Public}_{\bullet j}) + \epsilon_{ij}
\end{split}
$$

The Level-1 equation is:

$$
\mathrm{Language~Score}_{ij} = \beta_{0j} + \beta_{1j}(\mathrm{Verbal~IQ}_{ij}) + \beta_{2j}(\mathrm{SES}_{ij}) + \epsilon_{ij}
$$

This equation indicates that students' post-test language scores are a function of a school-specific intercept, a school-specific effect of verbal IQ scores, a school-specific effect of SES, and random error. There are now three Level-2 equations:

$$
\begin{split}
\beta_{0j} &= \beta_0 + \beta_4(\mathrm{Public}_{\bullet j}) + b_{0j}\\
\beta_{1j} &= \beta_1\\
\beta_{2j} &= \beta_2\\
\end{split}
$$

These equations indicates that each school-specific intercept is a function of a fixed, or common, intercept, the type of school, and random error. The effects of verbal IQ scores, pre-test language scores, and SES are constant, or fixed, across schools (there is not a random-effect in any of the last three Level-2 equations).


## Going from Multilevel Equations to the Mixed-Effects Model

If we have the multilevel equations, we can substitute the Level-2 equation(s) into the Level-1 equation to get the composite equation or mixed-effects equation. For example, for Model 2, substituting $\beta_0 + b_{0j}$ into $\beta_{0j}$ and $\beta_1$ into $\beta_{1j}$ gives us:

$$
\mathrm{Language~Score}_{ij} = \beta_{0} + b_{0j} + \beta_{1}(\mathrm{Verbal~IQ}_{ij}) + \epsilon_{ij}
$$

Similarly substituting the Level-2 information into the Level-1 equation for Model 3, we end up the following mixed-effects represenation:

$$
\begin{split}
\mathrm{Language~Score}_{ij} &= \bigg[\beta_0 + \beta_4(\mathrm{Public}_{\bullet j}) + b_{0j}\bigg] + \beta_1(\mathrm{Verbal~IQ}_{ij}) + \beta_2(\mathrm{SES}_{ij})  + \epsilon_{ij}
\end{split}
$$

Which, if we re-arrange terms gives us the same mixed-effects model that we started with. This substitution also helps us think about which Level-2 equation we put the the school-level predictors in. For example, what if we would have put the school type (`public`) predictor into the Level-2 equation associated with verbal IQ?


$$
\begin{split}
\mathbf{Level\mbox{-}1:}\\
&~ \mathrm{Language~Score}_{ij} = \beta_{0j} + \beta_{1j}(\mathrm{Verbal~IQ}_{ij}) + \beta_{2j}(\mathrm{SES}_{ij}) + \epsilon_{ij}\\
\mathbf{Level\mbox{-}2:}\\
&~ \beta_{0j} = \beta_0 + b_{0j}\\
&~ \beta_{1j} = \beta_1 + \beta_4(\mathrm{Public}_{\bullet j})\\
&~ \beta_{2j} = \beta_2\\
&~ \beta_{3j} = \beta_3\\
\end{split}
$$

If we substitute back into the Level-1 equation, the composite equation is:

$$
\begin{split}
\mathrm{Language~Score}_{ij} &= \bigg[\beta_0 + b_{0j}\bigg] + \bigg[\beta_1 + \beta_4(\mathrm{Public}_{\bullet j}) \bigg](\mathrm{Verbal~IQ}_{ij}) + \beta_2(\mathrm{SES}_{ij}) + \epsilon_{ij} \\[1em]
&= \big[\beta_0 + b_{0j}\big] + \beta_1(\mathrm{Verbal~IQ}_{ij}) + \beta_4(\mathrm{Public}_{\bullet j})(\mathrm{Verbal~IQ}_{ij}) + \beta_2(\mathrm{SES}_{ij}) + \epsilon_{ij}
\end{split}
$$

Adding the school type predictor in the verbal IQ equation produces an interaction term (product terms) in the composite equation! Adding them to the intercept equation produced main-effects. Since our orginal mixed-effects model included school type as a main-effect, we need to include them in the intercept equation. Note that if the composite equation included both a main-effect and an interaction, we would need to include the predictor in more than one of the Level-2 equations (e.g., in the intercept equation and the verbal IQ equation).

> Any predictors included in the Level-2 slope equations also need to be included in the Level-2 intercept equation.


## Guidelines for Writing the Multilevel Equations

Here are some guidelines in helping you think about writing multilevel equations.

- Write the Level-1 equation first. This will be an equation that expresses the outcome's relationship to a series of school-specific parameters and a student-specific residual.
- The number of school-specific parameters in the Level-1 equation (aside from the residual) dictate the number of Level-2 equations you will have.
- The school-specific parameters from the Level-1 equation will be the outcomes in the Level-2 equations.
- Random-effects are the residuals in the Level-2 equations, and therefore are in the Level-2 equations; one per equation.
- Variables from the data go to their appropriate level. For example student-level variables will be put in the Level-1 equation, and school-level predictors will be put in one or more of the Level-2 equations.

\newpage

# Multilevel Equations for Fixed-Effects Models

Our conventional fixed-effects regression models (LM) can also be expressed as a multilevel model. For example, consider the fixed-effect model that includes an intercept and effect of verbal IQ score:

$$
\mathrm{Language~Score}_{i} = \beta_{0} + \beta_{1}(\mathrm{Verbal~IQ}_{i}) + \epsilon_{i}
$$

The multilevel model would specify that the Level-2 equations would only include fixed-effects (no random-effects). Thus when we substitute them back into the Level-1 model we only have fixed-effects in the model:

$$
\begin{split}
\mathbf{Level\mbox{-}1:}\\
&~ \mathrm{Language~Score}_{ij} = \beta_{0j} + \beta_{1j}(\mathrm{Verbal~IQ}_{ij}) + \epsilon_{ij}\\
\mathbf{Level\mbox{-}2:}\\
&~ \beta_{0j} = \beta_{0}\\
&~ \beta_{1j} = \beta_{1}
\end{split}
$$

# Why are Multilevel Expressions Helpful?

Expressing the model as a set of multilevel equations can be helpful for readers. First, it explicitly separates the sources of variation and the predictors of these sources of variation into different levels. In our example there are two sources of variation student-level variation (within-school) and school-level variation (between-school). The Level-1 model attempts to describe the within-school variation and, hence, only includes student-level predictors. The Level-2 models attempts to describe the between-school variation and only includes school-level predictors.

Secondly, the multilevel expression of the model helps us think aboout what the predictors at each level are actually doing. Level-1 predictors explain variation in the outcome. In our example, they are explaining variation in students' post-test language scores. The Level-2 predictors are explaining variation in the school-specific intercepts (or intercepts and slopes)---they explain Level-2 variation.

Thirdly, the multilevel expression of the model helps us see that the random-effects are residuals; they are residuals of the Level-2 models. This helps us think about the more general statistical model. For example, the general statistial model for a model that includes fixed-effects of two predictors and a random-effect of intercept is:

$$
\begin{split}
\mathbf{Level\mbox{-}1:}\\
&~ Y_{ij} = \beta_{0j} + \beta_{1j}(X_{1ij}) + \beta_{2j}(X_{2ij})  + \epsilon_{ij}\\
\mathbf{Level\mbox{-}2:}\\
&~ \beta_{0j} = \beta_{0} + b_{0j}\\
&~ \beta_{1j} = \beta_{1} \\
&~ \beta_{2j} = \beta_{2}
\end{split}
$$

where

$$
\begin{split}
\epsilon_{ij} &\sim \mathcal{N}\bigg(0,\sigma^2_{\epsilon}\bigg)\\[1em]
b_{0j} &\sim \mathcal{N}\bigg(0,\sigma^2_{0}\bigg)
\end{split}
$$

In the mixed-effects model we put distributional assumptions on both the Level-1 residuals and the Level-2 residuals.


## Evaluating the Assumptions: An Example

Evaluating the assumptions in a mixed-effects model is a bit more complicated than it is in a fixed-effects model, and there are several things to check depending on the model that was fitted (among other things, the number of random-effects and their covariance structure). To simplify things, in this course, we will evaluate the distributional assumptions placed on the Level-1 residuals, and we will also evaluate the normality assumption on the random-effects.

To illustrate assumption checking in practice, we will evaluate the assumptions for fitting Model 3. Recall that the multilevel expression of Model 3 was:

$$
\begin{split}
\mathbf{Level\mbox{-}1:}\\
&~ \mathrm{Language~Score}_{ij} = \beta_{0j} + \beta_{1j}(\mathrm{Verbal~IQ}_{ij}) + \beta_{2j}(\mathrm{SES}_{ij}) + \epsilon_{ij}\\
\mathbf{Level\mbox{-}2:}\\
&~ \beta_{0j} = \beta_0 + \beta_4(\mathrm{Public}_{\bullet j}) + b_{0j}\\
&~ \beta_{1j} = \beta_1 \\
&~ \beta_{2j} = \beta_2\\
\end{split}
$$

The assumptions are based on the Level-1 residuals ($\epsilon_{ij}$) and the Level-2 residuals, or random-effects ($b_{0j}$). So we need to examine the distributions of those two components. To begin, we will fit the mixed-effects model.

```{r}
# Fit Model 3
lmer.3 = lmer(language_post ~ 1 + verbal_iq + ses + public + (1 | school_id),
              data = joined_data, REML = FALSE)
```


## Evaluate Assumptions about the Level-1 Residuals

We will evaluate the Level-1 residuals in the exact same way we evalauted the residuals from a fixed-effects (LM) analysis. The `augment()` function from the **broom** package produces the Level-1 residuals and fitted values.

```{r}
# Augment the model to get the Level-1 residuals and fitted values
out_3 = augment(lmer.3)
head(out_3)
```

\newpage

The Level-1 residuals are found in the `.resid` column, and the `.fitted` column contains the $\hat{Y}$ values. As with LM residual analysis, we want to examine the normality of the residuals in a density plot (or some other plot that allows you to evaluate this), and the other assumptions by plotting the residuals against the fitted values in a scatterplot.

```{r fig.width=6, fig.height=6, out.width='2.75in', fig.show='hold', fig.cap='Plots to evaluate the Level-1 residuals.', fig.pos='H'}
# Density plot of the level-1 residuals
sm.density(out_3$.resid, model = "normal")

# Scatterplot of the Level-1 residuals versus the fitted values
ggplot(data = out_3, aes(x = .fitted, y = .resid)) +
  geom_point() +
  geom_hline(yintercept = 0) +
  theme_bw() +
  xlab("Fitted values") +
  ylab("Level-1 residuals")
```



Based on the plots, some of the distributional assumptions for the Level-1 residuals seem reasonably satisfied. The density plot suggests that the normality assumption is tenable, and the scatterplot shows symmetry around the $Y=0$ line (linearity). The assumption of homoskedasticity is more in question. The pattern in the residuals shows more variation for fitted values between 30 and 50, and less variation for smaller and larger fitted values.


## Assumptions about the Random-Effects

We also need to examine the assumptions for any random-effects included in the model. For this course, we will examine the normaility assumption. In our example that means we need to examine the normality assumption about the intercept random-effects. To do this we need to extract the random-effects from the model so we can use the `sm.density()` function to evaluate normality.


```{r out.width='2.75in', fig.cap='Density plot of the estimated random-effects for intercept.', fig.pos='H'}
# Obtain the intercept random-effects
re_int = ranef(lmer.3)$school_id[ , 1]

# Density plot of the RE for intercept
sm.density(re_int, model = "normal", xlab = "RE for intercept")
```


This assumption looks reasonably satisfied.



