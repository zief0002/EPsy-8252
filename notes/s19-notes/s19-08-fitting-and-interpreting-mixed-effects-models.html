<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />



<meta name="date" content="2018-03-30" />

<title>Fitting and Interpreting Mixed-Effects Models</title>

<script src="s19-08-fitting-and-interpreting-mixed-effects-models_files/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="s19-08-fitting-and-interpreting-mixed-effects-models_files/bootstrap-3.3.5/css/flatly.min.css" rel="stylesheet" />
<script src="s19-08-fitting-and-interpreting-mixed-effects-models_files/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="s19-08-fitting-and-interpreting-mixed-effects-models_files/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="s19-08-fitting-and-interpreting-mixed-effects-models_files/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="s19-08-fitting-and-interpreting-mixed-effects-models_files/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="s19-08-fitting-and-interpreting-mixed-effects-models_files/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="s19-08-fitting-and-interpreting-mixed-effects-models_files/tocify-1.9.1/jquery.tocify.js"></script>
<script src="s19-08-fitting-and-interpreting-mixed-effects-models_files/navigation-1.1/tabsets.js"></script>
<link href="s19-08-fitting-and-interpreting-mixed-effects-models_files/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="s19-08-fitting-and-interpreting-mixed-effects-models_files/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>



<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Fitting and Interpreting Mixed-Effects Models</h1>
<h4 class="date"><em>2018-03-30</em></h4>

</div>


<div id="preparation" class="section level1">
<h1>Preparation</h1>
<p>We will again use the data from the files <em>netherlands-level1.csv</em> and <em>netherlands-level2.csv</em>. Below we load several R packages and import both datasets.</p>
<pre class="r"><code># Load libraries
library(AICcmodavg)
library(broom)
library(dplyr)
library(ggplot2)
library(lme4) #for fitting mixed-effects models
library(readr)
library(sm)

# Read in student-level data
level_1 = read_csv(file = &quot;~/Dropbox/epsy-8252/data/netherlands-level-1.csv&quot;)
head(level_1)</code></pre>
<pre><code>## # A tibble: 6 x 8
##   student_id school_id language_pre language_post   ses verbal_iq female
##        &lt;int&gt;     &lt;int&gt;        &lt;int&gt;         &lt;int&gt; &lt;int&gt;     &lt;dbl&gt;  &lt;int&gt;
## 1      17001         1           36            46    23     3.17       0
## 2      17002         1           36            45    10     2.67       0
## 3      17003         1           33            33    15    -2.33       0
## 4      17004         1           29            46    23    -0.834      0
## 5      17005         1           19            20    10    -3.83       0
## 6      17006         1           22            30    10    -2.33       0
## # ... with 1 more variable: minority &lt;int&gt;</code></pre>
<pre class="r"><code># Read in team-level data
level_2 = read_csv(file = &quot;~/Dropbox/epsy-8252/data/netherlands-level-2.csv&quot;)
head(level_2)</code></pre>
<pre><code>## # A tibble: 6 x 5
##   school_id school_type school_ses school_verbal_iq school_minority
##       &lt;int&gt; &lt;chr&gt;            &lt;int&gt;            &lt;dbl&gt;           &lt;int&gt;
## 1         1 Public              11           -1.51               60
## 2         2 Public              11           -2.83               10
## 3        10 Public              15           -1.33                4
## 4        12 Public              20           -2.40                5
## 5        15 Catholic            18           -0.334              25
## 6        16 Protestant          13           -0.147               0</code></pre>
<pre class="r"><code># Merge the two datasets
full_data = left_join(level_1, level_2, by = &quot;school_id&quot;)
head(full_data)</code></pre>
<pre><code>## # A tibble: 6 x 12
##   student_id school_id language_pre language_post   ses verbal_iq female
##        &lt;int&gt;     &lt;int&gt;        &lt;int&gt;         &lt;int&gt; &lt;int&gt;     &lt;dbl&gt;  &lt;int&gt;
## 1      17001         1           36            46    23     3.17       0
## 2      17002         1           36            45    10     2.67       0
## 3      17003         1           33            33    15    -2.33       0
## 4      17004         1           29            46    23    -0.834      0
## 5      17005         1           19            20    10    -3.83       0
## 6      17006         1           22            30    10    -2.33       0
## # ... with 5 more variables: minority &lt;int&gt;, school_type &lt;chr&gt;,
## #   school_ses &lt;int&gt;, school_verbal_iq &lt;dbl&gt;, school_minority &lt;int&gt;</code></pre>
<div id="fitting-the-mixed-effects-regression-model-in-practice" class="section level2">
<h2>Fitting the Mixed-Effects Regression Model in Practice</h2>
<p>In practice, we use the <code>lmer()</code> function from the <strong>lme4</strong> library to fit mixed-effect regression models. This function will essentially do what we conceptually did in the previous set of notes, but rather than independently fitting the school-specific models and the global model, it will fit all these models simultaneously and make use of the information in all the clusters (schools) to do this. This will result in better estimates for both the fixed- and random-effects.</p>
<p>The syntax looks similar to the syntax we use in <code>lm()</code> except now we split it into two parts. The first part of the syntax gives a model formula to specify the outcome and fixed-effects included in the model. This is identical to the syntax we used in the <code>lm()</code> function. In our example: <code>language_post ~ 1 + verbal_iq</code> indicating that we want to fit a model that includes fixed-effects for both the intercept and the effect of verbal IQ score. This specifies the global model</p>
<p>We also have to declare that we want to fit a model for each school. To do this, we will include a random-effect for intercept. (We could also include a random-effect of verbal IQ, but to keep it simpler right now, we only include the RE of intercept.) The second part of the syntax declares this: <code>(1 | school_id)</code>. This says fit school-specific models that vary in their intercepts. This is literally added to the fixed-effects formula using <code>+</code>. The complete syntax is:</p>
<pre class="r"><code># Fit mixed-effects regression model
lmer.1 = lmer(language_post ~ 1 + verbal_iq + (1 | school_id), data = full_data)</code></pre>
<p>To view the fixed-effects, we use the <code>fixef()</code> function.</p>
<pre class="r"><code>fixef(lmer.1)</code></pre>
<pre><code>## (Intercept)   verbal_iq 
##   40.608232    2.487591</code></pre>
<p>This gives the coefficients for the global model,</p>
<p><span class="math display">\[
\hat{\mathrm{Language~Score}_{ij}} = 40.61 + 2.49(\mathrm{Verbal~IQ}_{ij})
\]</span></p>
<p>We interpret these coefficients exactly like <code>lm()</code> coefficients. Here,</p>
<ul>
<li>The average language score for students with a verbal IQ score of 0 is predicted to be 40.61.</li>
<li>Each one-point difference in verbal IQ score is associated with a 2.49-point difference in language scores, on average.</li>
</ul>
<p>To view the school-specific random-effects, we use the <code>ranef()</code> function (only the first 6 rows are shown).</p>
<pre class="r"><code>ranef(lmer.1)</code></pre>
<table class="table table-striped" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;font-weight: bold;color: white;background-color: #d7261e;">
</th>
<th style="text-align:right;font-weight: bold;color: white;background-color: #d7261e;">
(Intercept)
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
1
</td>
<td style="text-align:right;">
-0.3757394
</td>
</tr>
<tr>
<td style="text-align:left;background-color: #d3d3d3;">
2
</td>
<td style="text-align:right;background-color: #d3d3d3;">
-6.0446989
</td>
</tr>
<tr>
<td style="text-align:left;">
10
</td>
<td style="text-align:right;">
-3.6648171
</td>
</tr>
<tr>
<td style="text-align:left;background-color: #d3d3d3;">
12
</td>
<td style="text-align:right;background-color: #d3d3d3;">
-2.9146344
</td>
</tr>
<tr>
<td style="text-align:left;">
15
</td>
<td style="text-align:right;">
-5.7435113
</td>
</tr>
<tr>
<td style="text-align:left;background-color: #d3d3d3;">
16
</td>
<td style="text-align:right;background-color: #d3d3d3;">
0.8105713
</td>
</tr>
</tbody>
</table>
<p>From these two sets of information, we can re-construct each school-specific fitted equation if we are so inclined. For example, to construct the school-specific fitted equation for School 1, we combine the estimated coefficients for the fixed-effects (global equation) and the estimated random-effect for School 1:</p>
<p><span class="math display">\[
\begin{split}
\hat{\mathrm{Language~Score}_{ij}} &amp;= \bigg[ 40.61 -0.376 \bigg]+ 2.49(\mathrm{Verbal~IQ}_{ij}) \\
&amp;= 40.2 + 2.49(\mathrm{Verbal~IQ}_{ij}) 
\end{split}
\]</span></p>
<!-- ## Variance Components: Quantifying Variation in the Random-Effects -->
<!-- Looking over the random-effects, it is clear that the random-effects for intercept vary across teams. The random-effects for slope also vary across team. It is common to quantify this variation by computing the standard deviation (or variance) for each set of random-effects. We can obtain these estimates by using the `VarCorr()` function. -->
<!-- ```{r} -->
<!-- VarCorr(lmer.1) -->
<!-- ``` -->
<!-- The output gives standard deviations of the random-effects. To get variances, we square these values. For example to obtain the variance component for the intercept random-effects, -->
<!-- ```{r} -->
<!-- 0.305 ^ 2 -->
<!-- ``` -->
<!-- There is also a standard deviation for the residuals. This is a measure of the variation in the player-level errors. Remember, even if we use a team-specific equation to predict life satisfaction, there will still be deviation between the predicted value and a player's actual life satisfaction.  -->
<!-- Recall that the goal in regression modeling is to explain variation. In a multilevel model, we can now try to explain between-team variation (the variation in intercepts and slopes) and within-team variation (residual). Comparing the size of the variance components, we see that the within-team variation (residual) is a lot larger than the between-team variation. This suggests that we may want to focus on including predictors that vary across players rather than on team-level predictors. -->
</div>
<div id="example-2-beauty-and-course-evaluations" class="section level2">
<h2>Example 2: Beauty and Course Evaluations</h2>
<p>In the second example, we will re-visit the question of whether perceived beauty of a profeesor impacts course evaluation scores. Recall that the data were collected from student evaluations of instructors’ beauty and teaching quality for several courses at the University of Texas. The source of these data is <span class="citation">Hamermesh &amp; Parker (2005)</span>; made available by <span class="citation">Gelman &amp; Hill (2007)</span>.</p>
<p>We actually have more nuanced data than we examined in EPsy 8251. The file <em>evaluations-level-2.csv</em> includes professor-level data for 94 professors. The variables in this data set are:</p>
<ul>
<li><code>prof_id</code>: Professor ID number</li>
<li><code>beauty</code>: Measure of the professor’s beauty. This is score is standardized (<span class="math inline">\(M=0\)</span>, <span class="math inline">\(SD=1\)</span>) so that a beauty rating of 0 represents the average beauty rating.</li>
<li><code>tenured</code>: Is the professor tenured? (0 = non-tenured; 1 = tenured)</li>
<li><code>native_english</code>: Is the professor a native english speaker? (0 = non-native English speaker; 1 = native English speaker)</li>
<li><code>age</code>: Professor’s age (in years)</li>
<li><code>female</code>: Is the professor a female? (0 = male; 1 = female)</li>
</ul>
<p>The file <em>evaluations-level-1.csv</em> includes data from 463 courses taught by these 94 professors. The variables in this data set are:</p>
<ul>
<li><code>prof_id</code>: Professor ID number</li>
<li><code>avg_eval</code>: Average course rating for the course</li>
<li><code>num_students</code>: Number of students enrolled in the course</li>
<li><code>perc_evaluating</code>: Percentage of enrolled students who completed a course evaluation</li>
</ul>
<p>To begin, we will import both the Level-1 and Level-2 datasets and then join them together.</p>
<pre class="r"><code># Read in level-1 data
eval_level_1 = read_csv(file = &quot;~/Dropbox/epsy-8252/data/evaluations-level-1.csv&quot;)
head(eval_level_1)</code></pre>
<pre><code>## # A tibble: 6 x 4
##   prof_id avg_eval num_students perc_evaluating
##     &lt;int&gt;    &lt;dbl&gt;        &lt;int&gt;           &lt;dbl&gt;
## 1       1     4.30           43            55.8
## 2       1     3.70          125            68.8
## 3       1     3.60          125            60.8
## 4       1     4.40          123            62.6
## 5       2     4.50           20            85.0
## 6       2     4.00           40            87.5</code></pre>
<pre class="r"><code># Read in level-2 data
eval_level_2 = read_csv(file = &quot;~/Dropbox/epsy-8252/data/evaluations-level-2.csv&quot;)
head(eval_level_2)</code></pre>
<pre><code>## # A tibble: 6 x 6
##   prof_id beauty tenured native_english   age female
##     &lt;int&gt;  &lt;dbl&gt;   &lt;int&gt;          &lt;int&gt; &lt;int&gt;  &lt;int&gt;
## 1       1  0.202       0              1    36      1
## 2       2 -0.826       1              1    59      0
## 3       3 -0.660       1              1    51      0
## 4       4 -0.766       1              1    40      1
## 5       5  1.42        0              1    31      1
## 6       6  0.500       1              1    62      0</code></pre>
<pre class="r"><code># Join the level-1 and level-2 datasets
evaluations = left_join(eval_level_1, eval_level_2, by = &quot;prof_id&quot;)
head(evaluations)</code></pre>
<pre><code>## # A tibble: 6 x 9
##   prof_id avg_eval num_students perc_evaluating beauty tenured
##     &lt;int&gt;    &lt;dbl&gt;        &lt;int&gt;           &lt;dbl&gt;  &lt;dbl&gt;   &lt;int&gt;
## 1       1     4.30           43            55.8  0.202       0
## 2       1     3.70          125            68.8  0.202       0
## 3       1     3.60          125            60.8  0.202       0
## 4       1     4.40          123            62.6  0.202       0
## 5       2     4.50           20            85.0 -0.826       1
## 6       2     4.00           40            87.5 -0.826       1
## # ... with 3 more variables: native_english &lt;int&gt;, age &lt;int&gt;, female &lt;int&gt;</code></pre>
<p>In these data, there are multiple courses for each professor. If we want to use these data to predict variation in course evaluation scores, we need to account for the fact that course evaluation scores are not independent of one another in this data. (Professors who have higher evaluations in one class also probably have higher evaluations in other classes.) To alleviate this problem, we can include a random-effect of intercept in our regression model.</p>
<div id="fit-a-mixed-effects-model" class="section level3">
<h3>Fit a Mixed-Effects Model</h3>
<p>Below we fit a mixed-effects regression model to predict variation in course evaluation scores that includes the following four predictors: number of students, percentage of students evaluating the course, beauty rating, and professor’s sex. To account for the dependency we also include a random-effect of intercept. The statistical model is:</p>
<p><span class="math display">\[
\mathrm{Avg.~Eval}_{ij} = \bigg[\beta_0 + b_{0j} \bigg] + \beta_1(\mathrm{Num.~Students}_{ij}) + \beta_2(\mathrm{Perc.~Evaluating}_{ij}) + \beta_3(\mathrm{Beauty~Rating}_{j}) + \beta_4(\mathrm{Female}_{j}) + \epsilon_{ij}
\]</span></p>
<p>We fit the model using <code>lmer()</code> as:</p>
<pre class="r"><code># Fit model
lmer.1 = lmer(avg_eval ~ 1 + num_students + perc_evaluating + beauty + female + 
                (1 | prof_id), data = evaluations)</code></pre>
<p>We can then extract the fixed-effects estimates using the <code>fixef()</code> function.</p>
<pre class="r"><code># Get fixed-effects
fixef(lmer.1)</code></pre>
<pre><code>##     (Intercept)    num_students perc_evaluating          beauty 
##     3.852944720    -0.001275042     0.003467759     0.137152463 
##          female 
##    -0.237142456</code></pre>
<p>These give the beta estimates in our global model. We write the fitted fixed-effects model (which ignores the random-effects) as:</p>
<p><span class="math display">\[
\hat{\mathrm{Avg.~Eval}_{ij}} = 3.85 - 0.001(\mathrm{Num.~Students}_{ij}) + 0.003(\mathrm{Perc.~Evaluating}_{ij}) + 0.137(\mathrm{Beauty~Rating}_{j}) - .237(\mathrm{Female}_{j})
\]</span></p>
<p>We can interpret these fixed-effects estimates the same way we do any other regression coefficient. Rather than interpret the raw numbers, below, we offer more general interpretations of these effects. (You can interpret the raw numbers exactly like we did in EPsy 8251. A one-unit difference in <span class="math inline">\(X\)</span> is associated with a <span class="math inline">\(\hat{\beta}\)</span>-difference in <span class="math inline">\(Y\)</span>, controlling for otehr predictors in the model.)</p>
<ul>
<li>The average course evaluation score when a course has 0 students enrolled, 0% of the students fill out course evaluations, the professor has an average beauty rating (rating = 0), and the professor is male is predicted to be 3.85. (Extrapolation!)</li>
<li>Larger classes tend to have lower average course evaluations, controlling for differences in all the other predictors in the model.</li>
<li>Course that have a higher percentages of students complete a course evaluation tend to have higher average course evaluation scores, controlling for the other predictors in the model.</li>
<li>Courses taught by professors with higher beauty ratings tend to have higher average course evaluation scores than courses taught by professors with lower beauty ratings, controlling for the other predictors in the model.</li>
<li>Courses taught by female professors tend to have lower average course evaluation scores than courses taught by male professors, controlling for the other predictors in the model.</li>
</ul>
<p>If we are interested in the fitted model for a SPECIFIC professor, we can extract the random-effect of intercept for that professor and add it to the fixed-effect estimate of estimate from the global model.</p>
<pre class="r"><code># Get random-effects (only first 10 are shown)
ranef(lmer.1)</code></pre>
<pre><code>##    (Intercept)
## 1   0.21520601
## 2  -0.33986369
## 3  -0.27465191
## 4   0.21554871
## 5   0.27554296
## 6   0.56272795
## 7   0.01522753
## 8   0.17163489
## 9   0.37621229
## 10  0.34651648</code></pre>
<p>For example, the fitted equation for Professor 1 is:</p>
<p><span class="math display">\[
\begin{split}
\hat{\mathrm{Avg.~Eval}_{ij}} &amp;= \bigg[3.85 + 0.2152\bigg] - 0.001(\mathrm{Num.~Students}_{ij}) + 0.003(\mathrm{Perc.~Evaluating}_{ij}) + 0.137(\mathrm{Beauty~Rating}_{j}) - .237(\mathrm{Female}_{j})\\
&amp;= 4.07 + - 0.001(\mathrm{Num.~Students}_{ij}) + 0.003(\mathrm{Perc.~Evaluating}_{ij}) + 0.137(\mathrm{Beauty~Rating}_{j}) - .237(\mathrm{Female}_{j})\\
\end{split}
\]</span></p>
<p>If we write the professor-specific equation for Professor 2:</p>
<p><span class="math display">\[
\begin{split}
\hat{\mathrm{Avg.~Eval}_{ij}} &amp;= \bigg[3.85 - 0.3399\bigg] - 0.001(\mathrm{Num.~Students}_{ij}) + 0.003(\mathrm{Perc.~Evaluating}_{ij}) + 0.137(\mathrm{Beauty~Rating}_{j}) - .237(\mathrm{Female}_{j})\\
&amp;= 3.51 + - 0.001(\mathrm{Num.~Students}_{ij}) + 0.003(\mathrm{Perc.~Evaluating}_{ij}) + 0.137(\mathrm{Beauty~Rating}_{j}) - .237(\mathrm{Female}_{j})\\
\end{split}
\]</span></p>
<p>Looking at these two equations gives us some insight into why the effects are referred to as <em>fixed-effects</em> or <em>random-effects</em>. In the two equations, the effect associated with each of the predictors is the same as in the global model. This implies that these effects have the exact same magnitude regardless of professor—they are fixed. On the other hand, the intercept value in the professor-specific equations are different. They vary by professor. Because of this we say that they are random-effects.</p>
</div>
</div>
</div>
<div id="references" class="section level1 unnumbered">
<h1>References</h1>
<div id="refs" class="references">
<div id="ref-Gelman:2007">
<p>Gelman, A., &amp; Hill, J. (2007). <em>Data analysis using regression and multilevel/hierarchical models</em>. New York: Cambridge University Press.</p>
</div>
<div id="ref-Hamermesh:2005">
<p>Hamermesh, D. S., &amp; Parker, A. M. (2005). Beauty in the classroom: Instructors’ pulchritude and putative pedagogical productivity. <em>Economics of Education Review</em>, <em>24</em>, 369–376.</p>
</div>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
