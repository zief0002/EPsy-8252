---
title: "Logistic Regression: Mixed-Effects Models"
date: "`r Sys.Date()`"
header-includes:
   - \usepackage{xcolor}
   - \usepackage[framemethod=tikz]{mdframed}
   - \usepackage{graphicx}
   - \usepackage{rotating}
   - \usepackage{booktabs}
   - \usepackage{float}
   - \usepackage{array}
   - \definecolor{umn}{RGB}{153, 0, 85}
   - \definecolor{umn2}{rgb}{0.1843137, 0.4509804, 0.5372549}
   - \definecolor{myorange}{HTML}{EA6153}
output: 
  pdf_document:
    latex_engine: xelatex
    highlight: zenburn
    fig_width: 6
    fig_height: 6
mainfont: "Sabon"
sansfont: "Futura"
monofont: Inconsolata
urlcolor: "umn2"
bibliography: epsy8252.bib
csl: apa-single-spaced.csl
always_allow_html: yes
---


```{r setup, include=FALSE}
options(digits = 3, scipen = 99)

library(knitr)
knitr::opts_chunk$set(
  prompt = FALSE,
  comment = NA,
  message = FALSE,
  warning = FALSE,
  tidy = FALSE,
  fig.align = 'center',
  out.width = '3in',
  echo = TRUE
  )

#library(printr)

options(kableExtra.latex.load_packages = FALSE)
library(kableExtra)
```

\frenchspacing


In this set of notes, you will learn about generalized mixed-effects models and how we can extend the logistic regression model to account for non-independence.


# Dataset and Research Question

In this set of notes, we will use data from the file *lsat.csv*. These data include the responses (correct = 1; incoreect = 0) for five items on the LSAT for $n=1000$ examineess.

```{r message=FALSE}
# Load libraries
library(AICcmodavg)
library(broom)
library(corrr)
library(dplyr)
library(ggplot2)
library(lme4)
library(readr)
library(sm)
library(tidyr)

# Read in data
lsat = read_csv(file = "~/Documents/github/epsy-8252/data/lsat.csv")

# View data
head(lsat)
```

Item response theory (IRT) is the dominant psychometric paradigm for analysis of assessment data. It also is the primary vehicle by which assessments are designed and scored. It is based on the simple idea that the probability of an examinee providing a correct response to an assessment item is a function of the examinee's "ability" and properties of the item.   

give each examinee a score on these five items. One way to do this is to sum all the items and give a total score. This method assumes that each item is interchangeable in contributing to the examinee's total test score. This is often an untenable assumption since in practice, we typically write assessment items to be non-interchangeable. For example, some items are more difficult than others.

In the 1950's, Georg Rasch was working on how to measure reading ability for the Danish military. He developed a theory of measurement (Rasch measurement) that laid out a probabilistic model for observing an examinee's response. In this model, the probability of an observed response (e.g. correct/incorrect answer) is modeled as a function of the examinee's ability (on some latent trait) and the test items' parameters. Specifically, the probability of a correct response is modeled as a logistic function of the difference between the examinee's ability and the item's difficulty parameter. 

$$
\pi_{ij} = \frac{e^{\theta_i - \beta_j}}{1 + e^{\theta_i - \beta_j}}
$$

where, $\pi_{ij}$ is the probability of examinee *i* responding correctly to item $j$, $\theta_i$ is examinee *i*'s ability level on the latent trait, and $\beta_j$ is the difficulty paramter of item *j*. We can also write this as log-odds,

$$
\begin{split}
\ln\bigg[\frac{\pi_{ij}}{1 - \pi_{ij}}\bigg] &= \ln\bigg[\frac{\frac{e^{\theta_i - \beta_j}}{1 + e^{\theta_i - \beta_j}}}{1 -\frac{e^{\theta_i - \beta_j}}{1 + e^{\theta_i - \beta_j}}}\bigg] \\[2ex]
&= \ln\bigg[\frac{\frac{e^{\theta_i - \beta_j}}{1 + e^{\theta_i - \beta_j}}}{\frac{1 + e^{\theta_i - \beta_j}}{1 + e^{\theta_i - \beta_j}} - \frac{e^{\theta_i - \beta_j}}{1 + e^{\theta_i - \beta_j}}}\bigg] \\[2ex]
&= \ln\bigg[\frac{\frac{e^{\theta_i - \beta_j}}{1 + e^{\theta_i - \beta_j}}}{\frac{1}{1 + e^{\theta_i - \beta_j}}}\bigg] \\[2ex]
&= \ln\bigg[e^{\theta_i - \beta_j}\bigg] \\[2ex]
&= \theta_i - \beta_j
\end{split}
$$

Thus, the log-odds of answering an item correctly is the difference between the examinee's ability level and the difficulty of the item.

# Expressing the Rasch Model using a Mixed-Effects Model

Consider a generalized mixed-effects model that includes a set of dummy variables indicating the item (no fixed-effect of intercept) and a random-effect of intercept. This model will use a binomial error structure and the logit link function to predict log-odds of answering the item correctly. For example, the model for three items will include three dummay variables:

- `item_01` = 1 if the item is the first item and 0 otherwise
- `item_02` = 1 if the item is the second item and 0 otherwise
- `item_03` = 1 if the item is the third item and 0 otherwise

We can include effects for all three dummy variables in the model if we omit the intercept from the model. Mathematically, we can write the link function as:

$$
\ln\bigg[\frac{\pi_{ij}}{1 - \pi_{ij}}\bigg] = \beta_1(\mathtt{Item\_01}_{ij}) + \beta_2(\mathtt{Item\_02}_{ij}) + \beta_3(\mathtt{Item\_03}_{ij}) + b_{0j}
$$

where *i* represents the *i*th item and *j* is the *j*th examinee. (Here item responses are clustered in examinees.)


Substituting the appropriate 0/1 values into the equation we end up with three equations, one for each item:

$$
\begin{split}
\mathbf{Item~1:~}&\ln\bigg[\frac{\pi_{ij}}{1 - \pi_{ij}}\bigg] = b_{0j} + \beta_1 \\[2ex]
\mathbf{Item~2:~}&\ln\bigg[\frac{\pi_{ij}}{1 - \pi_{ij}}\bigg] = b_{0j} + \beta_2 \\[2ex]
\mathbf{Item~3:~}&\ln\bigg[\frac{\pi_{ij}}{1 - \pi_{ij}}\bigg] = b_{0j} + \beta_3 \\[2ex]
\end{split}
$$

Notice that this is essentially the same equation as is produced by Rasch. The ability paramater is equivalent to the random-effect in the mixed-effect model. The $\beta$-terms are related to the difficulty parameters in the Rasch model. The only difference is that Rasch expressed his model as a *difference* and the mixed-effects model is expressed as a *sum*. In the mixed-effects models, the $\beta$-terms represent **item easiness** rather than item difficulty.

We can easily re-express the mixed-effects model using a difference rather than a sum:

$$
\begin{split}
\mathbf{Item~1:~}&\ln\bigg[\frac{\pi_{ij}}{1 - \pi_{ij}}\bigg] = b_{0j} - (-\beta_1) \\[2ex]
\mathbf{Item~2:~}&\ln\bigg[\frac{\pi_{ij}}{1 - \pi_{ij}}\bigg] = b_{0j} - (-\beta_2) \\[2ex]
\mathbf{Item~3:~}&\ln\bigg[\frac{\pi_{ij}}{1 - \pi_{ij}}\bigg] = b_{0j} - (-\beta_3) \\[2ex]
\end{split}
$$

Thus, if we want item difficulties, we simply need to take the negative of the $\beta$-terms.

# Fitting the Rasch Model using `glmer()`

Prior to fitting the mixed-effects model we need to convert our data from the wide to the long/tidy format.

```{r}
# Re-structure to long format
lsat_long = lsat %>%
  gather(key = "item", value = "correct", item_01:item_05) %>%
  arrange(examinee, item)

# View data
head(lsat_long, 15)
```

Now, we fit a model using the `glmer()` function that includes fixed-effects (dummy variables) for each of the five items and a random-effect of intercept. Importantly, we also omit the fixed-effect of intercept from the model. To do this we use `-1` rather than `1` in the fixed-effects part of the model formula. We define this model to incorporate a binomial error structure and use the logit link function.

```{r}
# The -1 omits the intercept
glmer.1 = glmer(correct ~ -1 + item + (1|examinee), data = lsat_long, family = binomial(link = "logit"))
summary(glmer.1)
```

Here the coefficient estimates represent item-easiness. To obtain the difficulty values we take the negative of each estimate.

```{r}
-fixef(glmer.1)
```

In Rasch's interpretation of item-difficulties, these represent the ability level needed to have a greater than 50/50 chance (odds = 1) of answering the item correctly. (Remember that ability is equivalent to the random-effect in the model and is therefore assumed to be normally distributed with a mean of 0; average ability = 0) 

For example, intepreting the item-difficulty estimate associated with Item 03:

> An examinee with ability of $-0.237$ (slightly less than average ability) would have a probability of 0.5 of answering Item 03 correctly. Examinees with ability levels below $-0.237$ would have a probability of less than 0.5 of answering the item correctly, and those with ability levels above $-0.237$ would have a probability higher than 0.5 of answering the item correctly.

All five items would be considered "easy" as the item-difficulty values are all negative, indicating that an examinee of average ability (=0) would all have a greater than 50/50 chance of answering them correctly.

## Examinee Ability-Levels

To obtain the ability-levels for the examinees, we need to ouput the estimated random-effects.

```{r}
# Extract the ability-levels
abilities = ranef(glmer.1)$examinee[ , 1]

# Output the first six examinees' ability-levels
head(abilities)
```

All six of these examinees have a below average (negative) ability-level. The first three examiness have the same ability-level ($-1.326$); as do the second three examinees ($-0.997$). Looking at the original LSAT data we see that these examinees have the same response patterns.

```{r}
head(lsat)
```

Namely the first three examinees answered each of the items incorrectly and the second three examinees answered all but Item 05 incorrectly. Subsequently, the estimated ability-level for the second three examinees is higher than for the first three examinees.

```{r}
lsat %>% 
  mutate(
    response_pattern = paste0(item_01, item_02, item_03, item_04, item_05),
    abilities = abilities,
    ability_1$score.dat$z1
      ) %>%
  distinct(response_pattern, .keep_all = TRUE)

```



Examinee 10 answered all of the items incorrectly except for Item 04.

```{r}
# Response pattern for Examinee 10
lsat[10, ]

# Ability-level for Examinee 10
abilities[10]
```

# Item Characteristic Curve

It can be useful to plot the probability of answering each item correctly for a range of examinee ability levels. This plot is referred to as an *item characteristic curve*. Below we outline the steps to create such a plot for Item 3.

- Compute the log-odds of answering Item 03 correctly for a range of ability levels using the item equation:

$$
\ln\bigg[\frac{\pi_{ij}}{1 - \pi_{ij}}\bigg] = b_{0j} - (-0.237) 
$$

- Convert the predicted log-odds to odds and then to probability.
- Plot the predicted probabilities versus the ability levels.

Here is some syntax to do this for Item 03.

```{r}
data.frame(
  b = seq(from = -4, to = 4, by = 0.1)
) %>%
  mutate(
    log_odds = b - (-0.237),
    odds = exp(log_odds),
    prob = odds / (1 + odds)
  ) %>%
  ggplot(aes(x = b, y = prob)) +
    geom_line() +
    theme_bw() +
    xlab("Ability level") +
    ylab("Probability of answering correctly") +
    ylim(0, 1)
    ggtitle("Item 03")
```

# Item Information



Another common plot in Rasch analysis is the item information plot. 

```{r}
data.frame(
  b = seq(from = -4, to = 4, by = 0.1)
) %>%
  mutate(
    log_odds = b - (-0.237),
    odds = exp(log_odds),
    prob = odds / (1 + odds),
    info = prob * (1 - prob)
  ) %>%
  ggplot(aes(x = b, y = info)) +
    geom_line() +
    theme_bw() +
    xlab("Ability level") +
    ylab("Information") +
    ggtitle("Item 03")
```



<!-- ## Other Resources {-} -->

<!-- In addition to the notes and what we cover in class, there many other resources for learning about using binomial logistic regression models for analyzing binary data. Here are some resources that may be helpful in that endeavor: -->

<!-- - Section 3.2.1: *The Binomial and Bernoulli Distributions* in Fox (2009) [Required Textbook] -->

